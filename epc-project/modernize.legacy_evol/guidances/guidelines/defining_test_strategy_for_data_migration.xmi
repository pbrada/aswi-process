<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmi:id="_rAOgoNoJEdm5N8vZEEaxbg" name="defining_test_strategy_for_data_migration,9.407365359850219E-305" guid="_rAOgoNoJEdm5N8vZEEaxbg" changeDate="2005-08-17T18:28:19.365-0700" version="7.1.0">
  <mainDescription>&lt;h3>&#xD;
    &lt;a id=&quot;Introduction&quot; name=&quot;Introduction&quot;>&lt;/a>Introduction&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    After migrating data as specified in the &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../modernize.legacy_evol/workproducts/database_migration_specification_5091901D.html&quot;&#xD;
    guid=&quot;{24309CAC-2A58-4011-B0F0-0A7D2FD58AEA}&quot;>Work Product: Data Migration Specification,&lt;/a> you need to validate the&#xD;
    correctness of the resulting data. This is a critical activity. Improperly converted data can lie dormant and cause&#xD;
    invalid results in the new system and, often worse, invalid results that remain undetected. Careful validation is&#xD;
    needed to prevent this time bomb effect. The risk is often heightened because of the volume of much of the data and&#xD;
    because the project team may have only indirect control of the conversion process.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    As with all testing activities, you should first define the test strategy that you will use to validate the migrated&#xD;
    data. In addition to what is described in &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../core.base_rup/tasks/subsystem_design_real-time_design_681F0256.html&quot;&#xD;
    guid=&quot;{30B2108A-294F-44EE-AC02-FFC1F70D67FF}&quot;>Task: Define Test Approach&lt;/a>, the following considerations should be&#xD;
    taken into account:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#Data_Accuracy&quot;>Data accuracy&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#Test_Auto_Data_Migration&quot;>Testing of Automated Data Migration&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#Control_Procedures&quot;>Control procedures&lt;/a>&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;Data_Accuracy&quot; name=&quot;Data_Accuracy&quot;>&lt;/a>Data Accuracy&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    In data migration, the resulting data may not always need to be completely accurate, as complete accuracy may be&#xD;
    uneconomic or impossible. You should define the level of accuracy that will be acceptable in your context. Here are&#xD;
    some examples:&lt;br />&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        For accounting applications, figures must be accurate but may be only at a summary level.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        For inventory applications, stock records for expensive items must be exact, but low cost items can be by weight or&#xD;
        volume and not necessarily by unit count.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        For some applications, such as large mailing list applications, it is rarely possible to transfer all source data&#xD;
        in fully validated output format nor to remove all duplicates. A small percentage of inaccuracy and duplication,&#xD;
        however, may not be a serious problem, as long as most of the data transfers successfully.&lt;br />&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;Test_Auto_Data_Migration&quot; name=&quot;Test_Auto_Data_Migration&quot;>&lt;/a>Testing of Automated Data Migration&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Special attention must be paid to automatically migrated data to ensure that there are no errors in the migration&#xD;
    software. Migrated data should be verified to ensure that an appropriate &lt;a href=&quot;#Data_Accuracy&quot;>level of accuracy&lt;/a>&#xD;
    has been achieved.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    When results fall outside the acceptable accuracy range, identify the causes and initiate corrective procedures, such&#xD;
    as:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Make required corrections to source data and re-run the conversion.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Identify corrections to the automated data conversion software (typically by creating a Change Request), and re-run&#xD;
        the conversion once the software has been fixed.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Note the data errors for manual correction on the new system.&lt;br />&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;Control_Procedures&quot; name=&quot;Control_Procedures&quot;>&lt;/a>Control Procedures&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Control procedures must be defined to ensure that all input data is completely and accurately converted. These&#xD;
    procedures can consist of manually checking all or a sampling of data before and after conversion or manually checking&#xD;
    of reports created from the data. The degree of validation required depends on the criticality of the data being&#xD;
    converted.&#xD;
&lt;/p></mainDescription>
</org.eclipse.epf.uma:ContentDescription>
