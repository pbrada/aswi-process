<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:TaskDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmi:id="_1ahDItnmEdmO6L4XMImrsA" name="describe_runtime_architecture,{4D35C038-A2D0-48B8-9ECD-52717FEAE33A}" guid="_1ahDItnmEdmO6L4XMImrsA" changeDate="2005-07-25T15:00:23.133-0700" version="7.1.0">
  <mainDescription>&lt;p>&#xD;
    Active objects (that is, instances of active classes) are used to represent concurrent threads of execution in the&#xD;
    system: notionally, each active object has its own thread of control, and, conventionally, is the root of an execution&#xD;
    stack frame. The mapping of active objects to actual operating system threads or processes may vary according to&#xD;
    responsiveness requirements, and will be influenced by considerations of context switching overhead. For example, it is&#xD;
    possible for a number of active objects, in combination with a simple scheduler, to share a single operating system&#xD;
    thread, thereby giving the appearance of running concurrently. However, if any of the active objects exhibits blocking&#xD;
    behavior, for example, by performing synchronous input-output, then other active objects in the group will be unable to&#xD;
    respond to events that occur while the operating system thread is blocked.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    At the other extreme, giving each active object its own operating system thread should result in greater&#xD;
    responsiveness, provided the processing resources are not adversely impacted by the extra context switching overhead.&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;reactive&quot;>&#xD;
    In real-time systems, &lt;a class=&quot;elementLinkWithType&quot; href=&quot;./../../core.base_rup/workproducts/rup_capsule_FC4A34FD.html&quot;&#xD;
    guid=&quot;{4423FCE1-FF59-4C8E-A6C4-AA4B13CB3250}&quot;>Artifact: Capsule&lt;/a>s are the recommended way of modeling concurrency;&#xD;
    like active classes, each capsule has its own notional thread of control, but capsules have additional encapsulation&#xD;
    and compositional semantics to make modeling of complex real-time problems more tractable.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    This task defines a process architecture for the system in terms of active classes and their instances and the&#xD;
    relationship of these to operating system threads and processes.&amp;nbsp;Equally, for real-time systems, the process&#xD;
    architecture will be defined in terms of capsules and an associated mapping of these to operating system processes and&#xD;
    threads.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Early in the Elaboration phase this architecture will be quite preliminary, but by late Elaboration the processes and&#xD;
    threads should be well-defined. The results of this task are captured in the design model - in particular, in the&#xD;
    process view (see &lt;a class=&quot;elementLinkWithType&quot; href=&quot;./../../core.base_rup/guidances/concepts/process_view_E3DD0B09.html&quot;&#xD;
    guid=&quot;6.45284088262517E-306&quot;>Concept: Process View&lt;/a>).&#xD;
&lt;/p></mainDescription>
  <sections xmi:id="_QRY-8NnnEdmO6L4XMImrsA" name="Analyze Concurrency Requirements " guid="_QRY-8NnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;Define Concurrency Requirements&quot; name=&quot;Define Concurrency Requirements&quot;>&lt;/a> &#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table&#xD;
    style=&quot;BORDER-RIGHT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-BOTTOM: rgb(128,128,128) 1px solid&quot;&#xD;
     cellspacing=&quot;0&quot; bordercolordark=&quot;#808080&quot; cellpadding=&quot;4&quot; width=&quot;100%&quot; bordercolorlight=&quot;#808080&quot; border=&quot;1&quot;>&#xD;
        &lt;tbody>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;5%&quot;>&#xD;
                    &lt;b>Purpose&amp;nbsp;&lt;/b>&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;95%&quot;>&#xD;
                    To define the extent to which parallel execution is required for the system. This definition will help&#xD;
                    shape the architecture.&amp;nbsp;&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
        &lt;/tbody>&#xD;
    &lt;/table>&lt;br />&#xD;
     During &lt;a class=&quot;elementLinkWithType&quot; href=&quot;./../../core.base_rup/tasks/identify_design_elements_E884AB82.html&quot;&#xD;
    guid=&quot;{97D7343A-6993-4AB7-8F86-4DAC8C9075C8}&quot;>Task: Identify Design Elements&lt;/a>, concurrency requirements driven&#xD;
    primarily by naturally occurring demands for concurrency in the problem domain were considered.&amp;nbsp;&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    The result of this was a set of active classes, representing logical threads of control in the system.&amp;nbsp; In&#xD;
    real-time systems, these active classes are represented by &lt;a class=&quot;elementLinkWithType&quot;&#xD;
    href=&quot;./../../core.base_rup/workproducts/rup_capsule_FC4A34FD.html&quot; guid=&quot;{4423FCE1-FF59-4C8E-A6C4-AA4B13CB3250}&quot;>Artifact:&#xD;
    Capsule&lt;/a>.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    In this step, we consider other sources of concurrency requirements - those imposed by the non-functional requirements&#xD;
    of the system.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Concurrency requirements are driven by:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;b>The degree to which the system must be distributed.&lt;/b> A system whose behavior must be distributed across&#xD;
        processors or nodes virtually requires a multi-process architecture. A system which uses some sort of Database&#xD;
        Management System or Transaction Manager also must consider the processes which those major subsystems introduce.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>The computation intensity of key algorithms.&lt;/b> In order to provide good response times, it may be necessary to&#xD;
        place computationally intensive activities in a process or thread of their own so that the system is still able to&#xD;
        respond to user inputs while computation takes place, albeit with fewer resources.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>The degree of parallel execution supported by the environment.&lt;/b> If the operating system or environment does&#xD;
        not support threads (lightweight processes) there is little point in considering their impact on the system&#xD;
        architecture.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>The need for fault tolerance in the system&lt;/b>. Backup processors require backup process, and drive the need to&#xD;
        keep primary and backup processes synchronized.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>The arrival pattern of events in the system.&lt;/b> In systems with external devices or sensors, the arrival&#xD;
        patterns of incoming events may differ from sensor to sensor. Some events may be periodic (i.e. occur at a fixed&#xD;
        interval, plus or minus a small amount) or aperiodic (i.e. with an irregular interval). Active classes representing&#xD;
        devices which generate different event patterns will usually be assigned to different operating system threads,&#xD;
        with different scheduling algorithms, to ensure that events or processing deadlines are not missed (if this is a&#xD;
        requirement of the system). This reasoning applies equally to capsules, when used in the design of real-time&#xD;
        systems.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    As with many architectural problems, these requirements may be somewhat mutually exclusive. It is not uncommon to have,&#xD;
    at least initially, conflicting requirements. Ranking requirements in terms of importance will help resolve the&#xD;
    conflict.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_QRY-8dnnEdmO6L4XMImrsA" name=" Identify Processes and Threads " guid="_QRY-8dnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;IdentifyProcessesAndThreads&quot; name=&quot;IdentifyProcessesAndThreads&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose&amp;nbsp;&lt;/b>&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To define the processes and threads which will exist in the system.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
     The simplest approach is to allocate all active objects to a common thread or process and use a simple active object&#xD;
    scheduler, as this minimizes context-switching overhead. However, in some cases, it may be necessary to distribute the&#xD;
    active objects across one or more threads or processes. This will almost certainly be the case for most real-time&#xD;
    systems, where the capsules used to represent the logical threads in some cases have to meet hard scheduling&#xD;
    requirements.&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    If an active object sharing an operating system thread with other active objects makes a synchronous call to some other&#xD;
    process or thread, and this call blocks the invoking object's shared operating system thread, then this will&#xD;
    automatically suspend all other active objects located in the invoking process. Now, this does not have to be the case:&#xD;
    a call that is synchronous from the point of view of the active object, may be handled asynchronously from the point of&#xD;
    view of the simple scheduler that controls the group of active objects - the scheduler suspends the active object&#xD;
    making the call (awaiting the completion of its synchronous call) and then schedules other active objects to run.&amp;nbsp;&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    When the original 'synchronous' operation completes, the invoking active object can be resumed. However, this approach&#xD;
    may not always be possible, because it may not be feasible for the scheduler to be designed to intercept all&#xD;
    synchronous calls before they block. Note that a synchronous invocation between active objects using the same operating&#xD;
    system process or thread can, for generality, be handled by the scheduler in this way - and is equivalent in effect to&#xD;
    a procedure call from the point of view of the invoking active object.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    This leads us to the conclusion that active objects should be grouped into processes or threads based on their need to&#xD;
    run concurrently with synchronous invocations that block the thread. That is, the only time an active object should be&#xD;
    packaged in the same process or a thread with another object that uses synchronous invocations that block the thread,&#xD;
    is if it does not need to execute concurrently with that object, and can tolerate being prevented from executing while&#xD;
    the other object is blocked. In the extreme case, when responsiveness is critical, this can lead to the need for a&#xD;
    separate thread or process for each active object.&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;reactive&quot;>&#xD;
    For real-time systems, the message-based interfaces of capsules mean that it is simpler to conceive a scheduler that&#xD;
    ensures, at least for capsule-to-capsule communications, that the supporting operating system threads are never&#xD;
    blocked, even when a capsule communicates synchronously with another capsule. However, it is still possible for a&#xD;
    capsule to issue a request directly to the operating system, for example, for a synchronous timed wait, that would&#xD;
    block the thread. Conventions have to be established, for lower level services invoked by capsules, that avoid this&#xD;
    behavior, if capsules are to share a common thread (and use a simple scheduler to simulate concurrency).&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    As a general rule, in the above situations it is better to use lightweight threads instead of full-fledged processes&#xD;
    since that involves less overhead. However, we may still want to take advantage of some of the special characteristics&#xD;
    of processes in certain special cases. Since threads share the same address space, they are inherently more risky than&#xD;
    processes. If the possibility of accidental overwrites is a concern, then processes are preferred. Furthermore, since&#xD;
    processes represent independent units of recovery in most operating systems, it may be useful to allocate active&#xD;
    objects to processes based on their need to recover independently of each other. That is, all active objects that need&#xD;
    to be recovered as a unit might be packaged together in the same process.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    For each separate flow of control needed by the system, create a process or a thread (lightweight process). A thread&#xD;
    should be used in cases where there is a need for nested flow of control (i.e. if, within a process, there is a need&#xD;
    for independent flow of control at the sub-task level).&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    For example, separate threads of control may be needed to do the following:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Separate issues between different areas of the software&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Take advantage of multiple CPUs in a node or multiple nodes in a distributed system&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Increase CPU utilization by allocating cycles to other activities when a thread of control is suspended&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Prioritize activities&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Support load sharing across several processes and processors&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Achieve a higher system availability by having backup processes&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Support the DBMS, Transaction Manager, or other major subsystems.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p class=&quot;exampleheading&quot;>&#xD;
    Example&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;example&quot;>&#xD;
    In the Automated Teller Machine, asynchronous events must be handled coming from three different sources: the user of&#xD;
    the system, the ATM devices (in the case of a jam in the cash dispenser, for example), or the ATM Network (in the case&#xD;
    of a shutdown directive from the network). To handle these asynchronous events, we can define three separate threads of&#xD;
    execution within the ATM itself, as shown below using active classes in UML.&#xD;
&lt;/p>&#xD;
&lt;p align=&quot;center&quot;>&#xD;
    &lt;img src=&quot;resources/proc1.gif&quot; alt=&quot;ATM Processes and Threads Illustration&quot; width=&quot;250&quot; height=&quot;362&quot; />&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;picturetext&quot;>&#xD;
    Processes and Threads within the ATM&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_QSbgwNnnEdmO6L4XMImrsA" name=" Identify Process Lifecycles " guid="_QSbgwNnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;XE_process__identifying_process_lifecycles&quot; name=&quot;XE_process__identifying_process_lifecycles&quot;>&lt;/a>&lt;a&#xD;
id=&quot;Identify Process Lifecycles&quot; name=&quot;Identify Process Lifecycles&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose&amp;nbsp;&lt;/b>&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To identify when processes and threads are created and destroyed.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Each process or thread of control must be created and destroyed. In a single-process architecture, process creation&#xD;
    occurs when the application is started and process destruction occurs when the application ends. In multi-process&#xD;
    architectures, new processes (or threads) are typically spawned or forked from the initial process created by the&#xD;
    operating system when the application is started. These processes must be explicitly destroyed as well.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The sequence of events leading up to process creation and destruction must be determined and documented, as well as the&#xD;
    mechanism for creation and deletion.&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;exampleheading&quot;>&#xD;
    Example&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;example&quot;>&#xD;
    In the Automated Teller Machine, one main process is started which is responsible for coordinating the behavior of the&#xD;
    entire system. It in turn spawns a number of subordinate threads of control to monitor various parts of the system: the&#xD;
    devices in the system, and events emanating from the customer and from the ATM Network. The creation of these processes&#xD;
    and threads can be shown with &lt;b>active classes&lt;/b> in UML, and the creation of instances of these active classes can&#xD;
    be shown in a sequence diagram, as shown below:&#xD;
&lt;/p>&#xD;
&lt;p align=&quot;center&quot;>&#xD;
    &lt;img src=&quot;resources/proc2.gif&quot; alt=&quot;System Start-Up Process and Thread Creation Illustration&quot; width=&quot;607&quot;&#xD;
    height=&quot;350&quot; />&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;picturetext&quot;>&#xD;
    Creation of processes and threads during system initialization&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_QTU4oNnnEdmO6L4XMImrsA" name=" Identify Inter-Process Communication Mechanisms " guid="_QTU4oNnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;XE_process__identifying_communication_mechanisms&quot; name=&quot;XE_process__identifying_communication_mechanisms&quot;>&lt;/a>&lt;a&#xD;
id=&quot;Identify Inter-Process Communication Mechanisms&quot; name=&quot;Identify Inter-Process Communication Mechanisms&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose&amp;nbsp;&lt;/b>&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To identify the means by which processes and threads will communicate.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Inter-process communication (IPC) mechanisms enable messages to be sent between objects executing in separate&#xD;
    processes.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Typical inter-process communications mechanisms include:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;b>Shared memory&lt;/b>, with or without semaphores to ensure synchronization.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>Rendezvous&lt;/b>, especially when directly supported by a language such as Ada&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>Semaphores&lt;/b>, used to block simultaneous access to shared resources&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>Message passing&lt;/b>, both point-to-point and point-to-multipoint&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>Mailboxes&lt;/b>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>RPC&lt;/b> - Remote procedure calls&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>Event Broadcast&lt;/b> - using a &quot;software bus&quot; (&quot;message bus architecture&quot;)&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    The choice of IPC mechanism will change the way the system is modeled; in a &quot;message bus architecture&quot;, for example,&#xD;
    there is no need for explicit associations between objects to send messages.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_QTU4odnnEdmO6L4XMImrsA" name=" Allocate Inter-Process Coordination Resources " guid="_QTU4odnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;Allocate Inter-Process Coordination Resources&quot; name=&quot;Allocate Inter-Process Coordination Resources&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose&lt;/b>&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To allocate scarce resources&lt;br />&#xD;
                 To anticipate and manage potential performance bottlenecks&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Inter-process communication mechanisms are typically scarce. Semaphores, shared memory, and mailboxes are typically&#xD;
    fixed in size or number and cannot be increased without significant cost. RPC, messages and event broadcasts soak up&#xD;
    increasingly scarce network bandwidth. When the system exceeds a resource threshold, it typically experiences&#xD;
    non-linear performance degradation: once a scarce resource is used up, subsequent requests for it are likely to have an&#xD;
    unpleasant effect.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    If scarce resources are unavailable, there are several strategies to consider:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        reducing the need for the scarce resource by reducing the number of processes&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        changing the usage of scarce resources (for one or more processes, choose a different, less scarce resource to use&#xD;
        for the IPC mechanism)&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        increasing the quantity of the scarce resource (e.g. increasing the number of semaphores). This can be done for&#xD;
        relatively small changes, but often has side effects or fixed limits.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        sharing the scarce resource (e.g. only allocating the resource when it is needed, then letting go when done with&#xD;
        it). This is expensive and may only forestall the resource crisis.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    Regardless what the strategy chosen, the system should degrade gracefully (rather than crashing), and should provide&#xD;
    adequate feedback to a system administrator to allow the problem to be resolved (if possible) in the field once the&#xD;
    system is deployed.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    If the system requires special configuration of the run-time environment in order to increase the availability of a&#xD;
    critical resource (often control by re-configuring the operating system kernel), the system installation needs to&#xD;
    either do this automatically, or instruct a system administrator to do this before the system can become operational.&#xD;
    For example, the system may need to be re-booted before the change will take effect.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_QTU4otnnEdmO6L4XMImrsA" name=" Map Processes onto the Implementation Environment " guid="_QTU4otnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;XE_process__map_process_onto_implementation_environment&quot;&#xD;
name=&quot;XE_process__map_process_onto_implementation_environment&quot;>&lt;/a>&lt;a&#xD;
id=&quot;Map Processes onto the Implementation Environment&quot; name=&quot;Map Processes onto the Implementation Environment&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To map the &quot;flows of control&quot; onto the concepts supported by the implementation environment.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Conceptual processes must be mapped onto specific constructs in the operating environment. In many environments, there&#xD;
    are choices of types of process, at the very least usually process and threads. The choices will be base on the degree&#xD;
    of coupling (processes are stand-alone, whereas threads run in the context of an enclosing process) and the performance&#xD;
    requirements of the system (inter-process communication between threads is generally faster and more efficient than&#xD;
    that between processes).&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    In many systems, there may be a maximum number of threads per process or processes per node. These limits may not be&#xD;
    absolute, but may be practical limits imposed by the availability of scarce resources. The threads and processes&#xD;
    already running on a target node need to be considered along with the threads and processes proposed in the process&#xD;
    architecture. The results of the earlier step, Allocate&lt;a&#xD;
    href=&quot;#Allocate%20Inter-Process%20Coordination%20Resources&quot;>Inter-Process Coordination Resources&lt;/a>, need to be&#xD;
    considered when the mapping is done to make sure that a new performance problem is not being created.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_QTU4o9nnEdmO6L4XMImrsA" name=" Map Design Elements To Threads of Control " guid="_QTU4o9nnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;XE_process__map_design_elements_to&quot; name=&quot;XE_process__map_design_elements_to&quot;>&lt;/a>&lt;a&#xD;
id=&quot;Map Design Elements To Threads of Control&quot; name=&quot;Map Design Elements To Threads of Control&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To determine which threads of control classes and subsystems should execute within.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Instances of a given class or subsystem must execute within at least &lt;b>one&lt;/b> thread of control that provides the&#xD;
    execution environment for the class or subsystem; they may in fact execute in several different processes.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Using two different strategies simultaneously, we determine the &quot;right&quot; amount of concurrency and define the &quot;right&quot;&#xD;
    set of processes:&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    Inside-out&#xD;
&lt;/h4>&#xD;
&lt;ol>&#xD;
    &lt;li>&#xD;
        Starting from the Design Model, group classes and subsystems together in sets of cooperating elements that (a)&#xD;
        closely cooperate with one another and (b) need to execute in the same thread of control. Consider the impact of&#xD;
        introducing inter-process communication into the middle of a message sequence before separating elements into&#xD;
        separate threads of control.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Conversely, separate classes and subsystems which do not interact at all, placing them in separate threads of&#xD;
        control.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        This clustering proceeds until the number of processes has been reduced to the smallest number that still allows&#xD;
        distribution and use of the physical resources.&#xD;
    &lt;/li>&#xD;
&lt;/ol>&#xD;
&lt;h4>&#xD;
    Outside-in&#xD;
&lt;/h4>&#xD;
&lt;ol>&#xD;
    &lt;li>&#xD;
        Identify external stimuli to which the system must respond. Define a separate thread of control to handle each&#xD;
        stimuli and a separate server thread of control to provide each service.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Consider the data integrity and serialization constraints to reduce this initial set of threads of control to the&#xD;
        number that can be supported by the execution environment.&#xD;
    &lt;/li>&#xD;
&lt;/ol>&#xD;
&lt;p>&#xD;
    This is not a linear, deterministic process leading to an optimal process view; it requires a few iterations to reach&#xD;
    an acceptable compromise.&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;exampleheading&quot;>&#xD;
    Example&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;example&quot;>&#xD;
    The following diagram illustrates how classes within the ATM are distributed among the processes and threads in the&#xD;
    system.&#xD;
&lt;/p>&#xD;
&lt;p align=&quot;center&quot;>&#xD;
    &lt;img src=&quot;resources/proc3.gif&quot; alt=&quot;ATM Class Distribution Across Processes and Threads Illustration&quot; width=&quot;574&quot;&#xD;
    height=&quot;403&quot; />&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;picturetext&quot;>&#xD;
    Mapping of classes onto processes for the ATM&#xD;
&lt;/p>&lt;br />&#xD;
&lt;br /></sectionDescription>
  </sections>
  <purpose>&lt;a id=&quot;Top&quot; name=&quot;Top&quot;>&lt;/a> &#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        To analyze concurrency requirements,&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        To identify processes and their lifecycles&amp;nbsp;&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        To identify inter-process communication mechanisms and&amp;nbsp;allocate inter-process coordination resources&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        To distribute model elements among processes.&#xD;
    &lt;/li>&#xD;
&lt;/ul></purpose>
</org.eclipse.epf.uma:TaskDescription>
