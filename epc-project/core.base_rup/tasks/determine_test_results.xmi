<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:TaskDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmi:id="_2zLfMNnmEdmO6L4XMImrsA" name="determine_test_results,{74E51E86-ECAB-4A61-9A88-FD358EE6F2B1}" guid="_2zLfMNnmEdmO6L4XMImrsA" changeDate="2005-11-04T08:05:38.400-0800" version="7.1.0">
  <sections xmi:id="_XEqCgNnnEdmO6L4XMImrsA" name=" Examine all test incidents and failures " guid="_XEqCgNnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;ExamineTestIncidentsandFailures&quot; name=&quot;ExamineTestIncidentsandFailures&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To investigate each incident and obtain detailed understanding of the resulting problems.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    In this task, the Test Logs are analyzed to determine the meaningful Test Results, regarding the differences between&#xD;
    the expected results and the actual results of each test. Identify and analyze each incident and failure in turn. Learn&#xD;
    as much as you can about each occurrence.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Check for duplicate incidents, common symptoms and other relationships between incidents. These conditions often&#xD;
    provide valuable insight into the root cause of a group of the incidents.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_XEqCgdnnEdmO6L4XMImrsA" name=" Create and maintain Change Requests " guid="_XEqCgdnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;CreateMaintainCRs&quot; name=&quot;CreateMaintainCRs&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To enter change request information into a tracking tool for assessment, management, and resolution.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Differences indicate potential defects in the Target Test Items and should be entered into a tracking system as&#xD;
    incidents or Change Requests, with an indication of the appropriate corrective actions that could be taken.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;b>Sub-topics:&lt;/b>&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#VerifyIncidentFacts&quot;>Verify incident facts&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#ClarifyCRDetail&quot;>Clarify Change Request details&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#CRSeverityPriority&quot;>Indicate relative impact severity and resolution priority&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#LogAnotherCR&quot;>Log additional Change Requests separately&lt;/a>&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;VerifyIncidentFacts&quot; name=&quot;VerifyIncidentFacts&quot;>Verify incident facts&lt;/a> &lt;a href=&quot;#CreateMaintainCRs&quot;>&lt;img&#xD;
    src=&quot;./../../core.base_rup/resources/top.gif&quot; alt=&quot;To top of page&quot; border=&quot;0&quot; width=&quot;26&quot; height=&quot;20&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Verify that there is accurate, supporting data available. Collate the data for attachment directly to the Change&#xD;
    Request, or reference where the data can be obtained separately.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Whenever possible, verify that the problem is reproducible. Reproducible problems have much more likelihood of&#xD;
    receiving developer attention and being subsequently fixed; a problem that cannot be reproduced both frustrates&#xD;
    development staff and will waste valuable programming resources in fruitless research. We recommend that you still log&#xD;
    these incidents, but that you consider identifying unreproducable incidents separately from the reproducible ones.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;ClarifyCRDetail&quot; name=&quot;ClarifyCRDetail&quot;>Clarify Change Request details&lt;/a> &lt;a href=&quot;#CreateMaintainCRs&quot;>&lt;img&#xD;
    src=&quot;./../../core.base_rup/resources/top.gif&quot; alt=&quot;To top of page&quot; border=&quot;0&quot; width=&quot;26&quot; height=&quot;20&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    It's important for Change Requests to be understandable, especially the headline. Make sure the headline is crisp and&#xD;
    concise, articulating clearly the specific issue. A brief headline is useful for summary defect listings and discussion&#xD;
    in &lt;a class=&quot;elementLink&quot; href=&quot;./../../core.base_rup/guidances/termdefinitions/ccb_59E01CD3.html&quot; target=&quot;_blank&quot;&#xD;
    guid=&quot;_x9h-49nmEdmO6L4XMImrsA&quot;>CCB&lt;/a> status meetings.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    It's important that the detailed description of the Change Request is unambiguous and can be easily interpreted. It's a&#xD;
    good idea to log your Change Requests as soon as possible, but take time to go back and improve and expand on your&#xD;
    descriptions before they are viewed by development staff.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Provide candidate solutions, as many as practical. This helps to reduce any remaining ambiguity in the description,&#xD;
    often helping to clarify. It also ensures increases the likelihood that the solution will be close to your exceptions.&#xD;
    Furthermore, it shows that the test team is not only prepared to find the problems, but also to help identify&#xD;
    appropriate solutions.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Other details to include are screen image captures, Test Data files, automated Test Scripts, output from diagnostic&#xD;
    utilities and any other information that would be useful to the developers in isolating and correcting the underlying&#xD;
    fault.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;CRSeverityPriority&quot; name=&quot;CRSeverityPriority&quot;>Indicate relative impact severity and resolution priority&lt;/a> &lt;a&#xD;
    href=&quot;#CreateMaintainCRs&quot;>&lt;img src=&quot;./../../core.base_rup/resources/top.gif&quot; alt=&quot;To top of page&quot; border=&quot;0&quot; width=&quot;26&quot;&#xD;
    height=&quot;20&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Provide an indication to the management and development staff of the severity of the problem. In larger teams the&#xD;
    actual resolution priority is normally left for the management team to determine, however you might allow individuals&#xD;
    to indicate their preferred resolution priority and subsequently adjust as necessary. As a general rule, we recommend&#xD;
    you assign Change Requests an average resolution priority by default, and raise or lower that priority on a&#xD;
    case-by-case basis as necessary.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    You may need to differentiate between the impact the Change Request will have on the production environment if it isn't&#xD;
    addressed and the impact the Change Request will have on the test effort if it isn't addressed; It's just as important&#xD;
    for the management team to know when a defect is impacting the testing effort as it is to be aware of severity to&#xD;
    users.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Sometimes it's difficult to see in advance why you need both attributes. It's possible that an incident may be really&#xD;
    severe, such as a system crash, but the actions required to reproduce it very unlikely to occur. In this case the team&#xD;
    may indicate it's severity as high, but indicate a very low resolution priority.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;LogAnotherCR&quot; name=&quot;LogAnotherCR&quot;>Log additional Change Requests separately&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Incidents often bare out the old adage&quot;Where there's smoke, there's fire&quot;; as you identify and log one Change Request,&#xD;
    you quite often identify other issues that need to be addressed. Avoid the temptation to simply add these additional&#xD;
    findings to the existing Change Request: if the information is directly related and helps to solve the existing issue&#xD;
    better, then that's OK. If the other issues are different, identifying them against an existing CR may result in those&#xD;
    issues not being actioned, not getting appropriate priority in their own right, or impacting the speed at which other&#xD;
    issues are addressed.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_XEqCgtnnEdmO6L4XMImrsA" name=" Analyze and evaluate status " guid="_XEqCgtnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;AnalyzeEvaluateStatus&quot; name=&quot;AnalyzeEvaluateStatus&quot;>&lt;/a> &#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table&#xD;
    style=&quot;BORDER-RIGHT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-BOTTOM: rgb(128,128,128) 1px solid&quot;&#xD;
     cellspacing=&quot;0&quot; bordercolordark=&quot;#808080&quot; cellpadding=&quot;4&quot; width=&quot;100%&quot; bordercolorlight=&quot;#808080&quot; border=&quot;1&quot;>&#xD;
        &lt;tbody>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;5%&quot;>&#xD;
                    &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;95%&quot;>&#xD;
                    To calculate and deliver the key measures and indicators of test.&amp;nbsp;&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
        &lt;/tbody>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    &lt;b>Sub-topics:&lt;/b>&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#IncidentData&quot;>Incident distribution&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#ExecutionCoverageData&quot;>Test execution coverage&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#CRData&quot;>Change Requests statistics&lt;/a>&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;IncidentData&quot; name=&quot;IncidentData&quot;>Incident distribution&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Analyze the incidents based on where they are distributed, such as functional area, quality risk, assigned tester and&#xD;
    assigned developer.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Look for patterns in the distribution, such as functional areas that appear to have above average defects count. Also&#xD;
    look for both developers and testers that may be overworked and where their quality of work is slipping&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;ExecutionCoverageData&quot; name=&quot;ExecutionCoverageData&quot;>Test execution coverage&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    To evaluate test execution coverage, you need to review the Test Logs and determine:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        The ratio between how many tests (Test Scripts or Test Cases) have been performed in this Test Cycle and a total&#xD;
        number of tests for all intended Target Test Items.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        The ratio of successfully performed test cases.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    The objective is to ensure that a sufficient number of the tests targeted for this Test Cycle have been executed&#xD;
    usefully. If this is not possible, or to augment that execution data, one or more additional test coverage criteria can&#xD;
    be identified, based upon:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Quality Risk or priority&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Specification-based coverage (Requirements etc.)&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Business need or priority&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Code-based coverage&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    See &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../core.base_rup/guidances/concepts/key_measures_of_test_62253EE4.html#Requirements-based%20test%20coverage&quot;&#xD;
    guid=&quot;5.312818155786224E-305&quot;>Concept: Key Measures of Test, Requirements-based test coverage&lt;/a>.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Record an present the Test Results in an Test Evaluation Report for this Test Cycle.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;CRData&quot; name=&quot;CRData&quot;>Change Requests statistics&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    To analyze defects, you need to review and analyze the measures chosen as part of your defect analysis strategy. The&#xD;
    most common defect measures used include the following different measures (often displayed in the form of a graph):&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;b>Defect Density&lt;/b> - the number of defects are shown as a function of one or two defect attributes (such as&#xD;
        distribution over functional area or quality risk compared to status or severity).&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>Defect Trend&lt;/b> - the defect count is shown as a function over time.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;b>Defect Aging&lt;/b> - a special defect density report in which the defect counts are shown as a function of the&#xD;
        length of time a defect remained in a given status (open, new, waiting-for-verification, etc.)&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    Compare the measures from this Test Cycle to the running totals for the current Iteration and those from the analysis&#xD;
    of previous iterations, to better understand the emerging trends over time.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    It is recommended you present the results in diagram form with supporting findings on request.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_XEqCg9nnEdmO6L4XMImrsA" name=" Make an assessment of the current quality experience " guid="_XEqCg9nnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;AssessCurrentQuality&quot; name=&quot;AssessCurrentQuality&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To give feedback on the current perceived or experienced quality in the software product.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&#xD;
    &lt;p>&#xD;
        Formulate a summary of the current quality experience, highlighting both good and bad aspects of the software&#xD;
        products quality.&#xD;
    &lt;/p>&#xD;
&lt;/div></sectionDescription>
  </sections>
  <sections xmi:id="_XEqChNnnEdmO6L4XMImrsA" name=" Make an assessment of outstanding quality risks " guid="_XEqChNnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;AssessQualityRisks&quot; name=&quot;AssessQualityRisks&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To provide feedback on what remaining areas of risk provide the most potential exposure to the&#xD;
                project.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Identify and explain those areas that have not yet been addressed in terms of quality risks and indicate what impact&#xD;
    and exposure this leaves the team.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Provide an indication of what priority you consider each outstanding quality risk to have, and use the priority to&#xD;
    indicate the order in which these issues should be addressed.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_XEqChdnnEdmO6L4XMImrsA" name=" Make an assessment of test coverage " guid="_XEqChdnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;TestCoverage&quot; name=&quot;TestCoverage&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To make a summary assessment of the test coverage analysis.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Based on the work in step &lt;a href=&quot;#ExecutionCoverageData&quot;>test execution coverage&lt;/a>, provide a brief summary&#xD;
    statement of the status and information the data represents.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_XEzMcNnnEdmO6L4XMImrsA" name=" Draft the Test Evaluation Summary " guid="_XEzMcNnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;GenerateTestEvaluationSummary&quot; name=&quot;GenerateTestEvaluationSummary&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To communicate the results of testing to stakeholders and make an objective assessment of quality and test&#xD;
                status.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Present the Test Results for this Test Cycle in a Test Evaluation Summary. This step is to develop the initial draft of&#xD;
    the summary. This is accomplished by assembling the previous information that has been gathered into a readable summary&#xD;
    report. Depending on the stakeholder audience and project context, the actual format and content of the summary will&#xD;
    differ.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Often it is a good idea to distribute the initial draft to a subset of stakeholders to obtain feedback that you can&#xD;
    incorporate before publishing to a broader audience.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_XEzMcdnnEdmO6L4XMImrsA" name=" Advise stakeholders of key findings " guid="_XEzMcdnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;AdviseStakeholdersFindings&quot; name=&quot;AdviseStakeholdersFindings&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To promote and publicize the Evaluation Summary as appropriate.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Using whatever means is appropriate, publicize this information. We recommend you consider posting these on a&#xD;
    centralized project site, or present them in regularly held status meetings to enable feedback to be gathered and next&#xD;
    actions to be determined.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Be aware that making evaluation summaries publicly available can sometimes be a sensitive political issue. Negotiate&#xD;
    with the development manager to present results in such a manner that they reflect an honest and accurate summary of&#xD;
    your findings, yet respect the work of the developers.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_XEzMctnnEdmO6L4XMImrsA" name=" Evaluate and verify your results " guid="_XEzMctnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;EvaluateResults&quot; name=&quot;EvaluateResults&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To verify that the task has been completed appropriately and that the resulting work products are&#xD;
                acceptable.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Now that you have completed the work, it is beneficial to verify that the work was of sufficient value, and that you&#xD;
    did not simply consume vast quantities of paper. You should evaluate whether your work is of appropriate quality, and&#xD;
    that it is complete enough to be useful to those team members who will make subsequent use of it as input to their&#xD;
    work. Where possible, use the checklists provided in RUP to verify that quality and completeness are &quot;good enough&quot;.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Have the people performing the downstream tasks that rely on your work as input take part in reviewing your interim&#xD;
    work. Do this while you still have time available to take action to address their concerns. You should also evaluate&#xD;
    your work against the key input work products to make sure you have represented them accurately and sufficiently. It&#xD;
    may be useful to have the author of the input work product review your work on this basis.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Try to remember that that RUP is an iterative delivery process and that in many cases work products evolve over time.&#xD;
    As such, it is not usually necessary-and is often counterproductive-to fully-form a work product that will only be&#xD;
    partially used or will not be used at all in immediately subsequent work. This is because there is a high probability&#xD;
    that the situation surrounding the work product will change-and the assumptions made when the work product was created&#xD;
    proven incorrect-before the work product is used, resulting in wasted effort and costly rework. Also avoid the trap of&#xD;
    spending too many cycles on presentation to the detriment of content value. In project environments where presentation&#xD;
    has importance and economic value as a project deliverable, you might want to consider using an administrative resource&#xD;
    to perform presentation tasks.&#xD;
&lt;/p>&lt;br />&#xD;
&lt;br /></sectionDescription>
  </sections>
  <purpose>&lt;a id=&quot;Top&quot; name=&quot;Top&quot;>&lt;/a>&lt;a id=&quot;XE_test__determining_results_of&quot; name=&quot;XE_test__determining_results_of&quot;>&lt;/a> &#xD;
&lt;p>&#xD;
    The purpose of this task is to:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Make ongoing summary evaluations of the perceived quality of the product&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Identify and capture the detailed Test Results&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Propose appropriate corrective actions to resolve failures in quality&#xD;
    &lt;/li>&#xD;
&lt;/ul></purpose>
</org.eclipse.epf.uma:TaskDescription>
