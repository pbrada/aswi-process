<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:TaskDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmi:id="_2e6fYtnmEdmO6L4XMImrsA" name="define_assessment_and_traceability_needs,{F6F9BB36-5A72-421E-B195-8937E0C46AF8}" guid="_2e6fYtnmEdmO6L4XMImrsA" changeDate="2005-11-04T07:55:48.081-0800" version="7.1.0">
  <sections xmi:id="_WHHcMNnnEdmO6L4XMImrsA" name=" Identify Assessment and Traceability Requirements " guid="_WHHcMNnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;IdentifyAssessmentTraceRequirements&quot; name=&quot;IdentifyAssessmentTraceRequirements&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To understand the deliverables for the software assessment process and elicit the associated&#xD;
                requirements.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Review the Iteration Plan and identify specific assessment needs for this forthcoming body of work. Ask stakeholders&#xD;
    what they require from both assessment and traceability.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Also, consider whether the test effort will be formally audited either during or at the conclusion of the testing&#xD;
    effort. Formal audit requirements might necessitate the retention of additional documentation and records as proof that&#xD;
    sufficient testing has been undertaken.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_WHHcMdnnEdmO6L4XMImrsA" name=" Consider Constraints " guid="_WHHcMdnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;ConsiderConstraints&quot; name=&quot;ConsiderConstraints&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To identify the constraints that will effect the ability (or the necessity) to implement the&#xD;
                requirements.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    While there is typically a unending list of &quot;wants&quot; you might be tempted to consider as requirements for traceability&#xD;
    and assessment strategies, it's important to focus on the most important &quot;needs&quot; that a) Provide essential information&#xD;
    to the project team and b) Can actually be tracked and measured. It is unlikely that you will have enough resource&#xD;
    available for your strategy to cater for more than what is essentially needed.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;b>Sub-topics:&lt;/b>&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#ConsiderQualityLevel&quot;>Acceptable quality level&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#ConsiderEnablers&quot;>Process and tool enablement&lt;/a>&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;ConsiderQualityLevel&quot; name=&quot;ConsiderQualityLevel&quot;>Acceptable quality level&lt;/a> &lt;a&#xD;
    href=&quot;#ConsiderConstraints&quot;>&lt;img src=&quot;./../../core.base_rup/resources/top.gif&quot; alt=&quot;To top of page&quot; border=&quot;0&quot; width=&quot;26&quot;&#xD;
    height=&quot;20&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    It's important to identify what level of quality will be considered &quot;good enough,&quot; and develop an appropriate&#xD;
    assessment strategy. Note that often quality dimensions wax and wane in importance and quality levels rise and fall in&#xD;
    the eyes of the stakeholders throughout the project lifecycle&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Review the QA Plan, review the Software Development Plan and interview the important stakeholders themselves directly&#xD;
    to determine what they consider will be an acceptable quality level.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;ConsiderEnablers&quot; name=&quot;ConsiderEnablers&quot;>Process and tool enablement&lt;/a> &lt;a href=&quot;#ConsiderConstraints&quot;>&lt;img&#xD;
    src=&quot;./../../core.base_rup/resources/top.gif&quot; alt=&quot;To top of page&quot; border=&quot;0&quot; width=&quot;26&quot; height=&quot;20&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    While you can probably imagine a world of effortless traceability and assessment at a low-level of granularity, the&#xD;
    reality is that it's difficult and usually uneconomic to implement such approaches. With sophisticated tool support, it&#xD;
    can still be difficult and time-consuming to manage low-level approaches to traceability; without supporting tools,&#xD;
    almost impossible. The software engineering process itself might place constraints on traceability: for example, if&#xD;
    traceability from tests to motivating requirements is desired, but the requirements themselves are not being carefully&#xD;
    managed, it might be impossible to implement this traceability.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Consider the constraints and limitations of both your software engineering process and tools, and choose an&#xD;
    appropriate, workable traceability and assessment approach accordingly.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_WHHcMtnnEdmO6L4XMImrsA" name=" Consider Possible Strategies " guid="_WHHcMtnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;ConsiderPossibleStrategies&quot; name=&quot;ConsiderPossibleStrategies&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To identify and outline one or more strategies that will facilitate the required assessment process. &amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Now that you have a better understanding of the assessment and traceability requirements, and of the constraints placed&#xD;
    on them by the desired quality level and available process and tool support, you need to consider the potential&#xD;
    assessment or evaluation strategies you could employ. For a more detailed treatment of possible strategies, we suggest&#xD;
    you read Cem Kaner's paper &quot;&lt;a href=&quot;http://www.kaner.com/pdfs/pnsqc00.pdf&quot; target=&quot;_blank&quot;>&lt;i>Measurement of the&#xD;
    Extent of Testing&lt;/i>&lt;/a>,&quot; October 2000. (&lt;a href=&quot;http://www.adobe.com/products/acrobat/alternate.html&quot;>Get Adobe&#xD;
    Reader&lt;/a>)&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;b>Sub-topics:&lt;/b>&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#TestCoverageStrategy&quot;>Test Coverage Analysis&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#ResultsStrategy&quot;>Test Results Analysis&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#DefectStrategy&quot;>Defect Analysis&lt;/a>&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;TestCoverageStrategy&quot; name=&quot;TestCoverageStrategy&quot;>Test Coverage Analysis&lt;/a> &lt;a&#xD;
    href=&quot;#ConsiderPossibleStrategies&quot;>&lt;img src=&quot;./../../core.base_rup/resources/top.gif&quot; alt=&quot;To top of page&quot; border=&quot;0&quot; width=&quot;26&quot;&#xD;
    height=&quot;20&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    There are many different approaches to test coverage, and no one coverage measure alone provides all the coverage&#xD;
    information necessary to form an assessment of the extent or completeness of the test effort. Note that different&#xD;
    coverage strategies take more or less effort to implement, and with any particular measurement category, there will&#xD;
    usually be a depth of coverage analysis at which point it becomes uneconomic to record more detailed information.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Some categories of test coverage measurement include: Requirements, Source Code, Product Claims and Standards. We&#xD;
    recommend you consider incorporating more than one coverage category in your test assessment strategy. In most cases,&#xD;
    test coverage refers to the planning and implementation of specific tests in the first instance. However, test coverage&#xD;
    metrics and their analysis are also useful to consider in conjunction with test results or defect analysis.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;ResultsStrategy&quot; name=&quot;ResultsStrategy&quot;>Test Results Analysis&lt;/a> &lt;a href=&quot;#ConsiderPossibleStrategies&quot;>&lt;img&#xD;
    src=&quot;./../../core.base_rup/resources/top.gif&quot; alt=&quot;To top of page&quot; border=&quot;0&quot; width=&quot;26&quot; height=&quot;20&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    A common approach to test results analysis is to simply refer to the number of results that were positive or negative&#xD;
    as a percentage of the total number of tests run. Our opinion, and the opinion of other practitioner in the test&#xD;
    community, is that this is a simplistic and incomplete approach to analyzing test results.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Instead, we recommend you analyze your test results in terms of relative trend over time. Within each test cycle,&#xD;
    consider the relative distribution of test failures across different dimensions such as the functional area being&#xD;
    tested, the type of quality risks being explored, the relative complexity of the tests and the test resources applied&#xD;
    to each functional area.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;DefectStrategy&quot; name=&quot;DefectStrategy&quot;>Defect Analysis&lt;/a> &lt;a href=&quot;#ConsiderPossibleStrategies&quot;>&lt;img&#xD;
    src=&quot;./../../core.base_rup/resources/top.gif&quot; alt=&quot;To top of page&quot; border=&quot;0&quot; width=&quot;26&quot; height=&quot;20&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    While defects themselves are obviously related to the results of the test effort, the analysis of defect data does not&#xD;
    provide any useful information about the progress of the test effort or the completeness or thoroughness of that&#xD;
    effort. However, a mistake made by some test teams and project managers is to use the current defect count to measure&#xD;
    the progress of testing or as a gauge to the quality of the developed software. Our opinion, and the opinion of other&#xD;
    practitioner in the test community, is that this is a meaningless approach.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Instead, we recommend you analyze the relative trend of the defect count over time to provide a measure of relative&#xD;
    stability. For example, assuming the test effort remains relatively constant, you would typically expect to see the new&#xD;
    defect discovery rate as measured against a regular time period &quot;bell curve&quot; over the course of the iteration; an&#xD;
    increasing discovery rate that peaks then tails off toward the end of the iteration. However, you'll need to provide&#xD;
    this information in conjunction with an analysis of other defect metrics such as: defect resolutions rates, including&#xD;
    an analysis of the resolution type; distribution of defects by severity; distribution of defects by functional area.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    With sophisticated tool support, you can perform complex analysis of defect data relatively easily; without appropriate&#xD;
    tool support it is a much more difficult proposition.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_WHQmINnnEdmO6L4XMImrsA" name=" Discuss Possible Strategies with Stakeholders " guid="_WHQmINnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;DiscussPossibleStrategies&quot; name=&quot;DiscussPossibleStrategies&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To gather feedback through initial stakeholder review and adjust the strategies as necessary.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Present the possible strategies to the various stakeholders. Typically you'd expect this to include a group made up&#xD;
    from the following roles; Project Manager, the Software Architect, the Development Manager, the System Analyst, the&#xD;
    Configuration &amp;amp; Change Manager, the Deployment Manager and the Customer Representative. Each of these roles has a&#xD;
    stakeholding in how quality is assessed.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Depending on the culture of the project, you should choose an appropriate format to present the possible strategies.&#xD;
    This might range from one or more informal meetings to a formal presentation or workshop session.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_WHQmIdnnEdmO6L4XMImrsA" name=" Define and Agree on the Assessment Strategy " guid="_WHQmIdnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;DefineAgreeAssessmentStrategy&quot; name=&quot;DefineAgreeAssessmentStrategy&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To gain stakeholder agreement on the strategy that will be used.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Take the feedback your receive from the discussions and refine the assessment strategy to a single strategy that&#xD;
    addresses the needs of all stakeholders.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Present the assessment strategy for final agreement and approval.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_WHQmItnnEdmO6L4XMImrsA" name=" Define Tool Requirements " guid="_WHQmItnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;DefineToolRequirements&quot; name=&quot;DefineToolRequirements&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To define the supporting tool configuration requirements that will enable the assessment process.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    As mentioned previously, with sophisticated tool support you can perform complex analysis of measurement data&#xD;
    relatively easily; without appropriate tool support it is a much more difficult proposition.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    For the following categories, consider what tool support you will need: Coverage and Traceability, Defect Analysis.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_WHQmI9nnEdmO6L4XMImrsA" name=" Evaluate and Verify Your Results " guid="_WHQmI9nnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;EvaluateResults&quot; name=&quot;EvaluateResults&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To verify that the task has been completed appropriately and that the resulting work products are&#xD;
                acceptable.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Now that you have completed the work, it is beneficial to verify that the work was of sufficient value, and that you&#xD;
    did not simply consume vast quantities of paper. You should evaluate whether your work is of appropriate quality, and&#xD;
    that it is complete enough to be useful to those team members who will make subsequent use of it as input to their&#xD;
    work. Where possible, use the checklists provided in RUP to verify that quality and completeness are &quot;good enough.&quot;&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Have the people performing the downstream tasks that rely on your work as input take part in reviewing your interim&#xD;
    work. Do this while you still have time available to take action to address their concerns. You should also evaluate&#xD;
    your work against the key input work products to make sure you have represented them accurately and sufficiently. It&#xD;
    might be useful to have the author of the input work product review your work on this basis.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Try to remember that that RUP is an iterative process and that in many cases work products evolve over time. As such,&#xD;
    it is not usually necessary-and is often counterproductive-to fully-form a work product that will only be partially&#xD;
    used or will not be used at all in immediately subsequent work. This is because there is a high probability that the&#xD;
    situation surrounding the work product will change-and the assumptions made when the work product was created proven&#xD;
    incorrect-before the work product is used, resulting in wasted effort and costly rework. Also avoid the trap of&#xD;
    spending too many cycles on presentation to the detriment of content value. In project environments where presentation&#xD;
    has importance and economic value as a project deliverable, you might want to consider using an administrative resource&#xD;
    to perform presentation tasks.&#xD;
&lt;/p>&lt;br />&#xD;
&lt;br /></sectionDescription>
  </sections>
</org.eclipse.epf.uma:TaskDescription>
