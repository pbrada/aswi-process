<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmi:id="_1aqNEdnmEdmO6L4XMImrsA" name="concurrency,1.5676516174458592E-304" guid="_1aqNEdnmEdmO6L4XMImrsA" changeDate="2005-06-21T09:32:40.548-0700" version="7.1.0">
  <mainDescription>&lt;a id=&quot;Top&quot; name=&quot;Top&quot;>&lt;/a>&lt;a id=&quot;XE_concurrency__guidelines_for&quot; name=&quot;XE_concurrency__guidelines_for&quot;>&lt;/a> &#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;Introduction&quot; name=&quot;Introduction&quot;>Introduction&lt;/a>&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    The art of good design is that of choosing the &quot;best&quot; way to meet a set of requirements. The art of good concurrent&#xD;
    system design is often that of choosing the simplest way to satisfy the needs for concurrency. One of the first rules&#xD;
    for designers should be to avoid reinventing the wheel. Good design patterns and design idioms have been developed to&#xD;
    solve most problems. Given the complexity of concurrent systems it only makes sense to use well-proven solutions and to&#xD;
    strive for simplicity of design.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;Concurrency approaches&quot; name=&quot;Concurrency approaches&quot;>Concurrency Approaches&lt;/a>&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Concurrent tasks that take place entirely within a computer, are called &lt;b>threads of execution&lt;/b>. Like all&#xD;
    concurrent tasks, threads of execution are an abstract concept since they occur in time. The best we can do to&#xD;
    physically capture a thread of execution is to represent its state at a particular instant in time.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The most direct way of representing concurrent tasks using computers is to dedicate a separate computer to each task.&#xD;
    However, this usually too expensive and is not always conducive to conflict resolution. It is common, therefore, to&#xD;
    support multiple tasks on the same physical processor through some form of &lt;b>multi-tasking&lt;/b>. In this case, the&#xD;
    processor and its associated resources such as memory and busses are shared. (Unfortunately, this sharing of resources&#xD;
    may also lead to new conflicts that were not present in the original problem.)&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The most common form of multi-tasking is to provide each task with a &quot;virtual&quot; processor. This virtual processor is&#xD;
    typically referred to as a &lt;b>process or task&lt;/b>. Normally, each process has its own address space that is logically&#xD;
    distinct from the address space of other virtual processors. This protects processes on conflicting with each other&#xD;
    against accidental overwrites of each other's memory. Unfortunately, the overhead required to switch the physical&#xD;
    processor from one process to another is often prohibitive. It involves significant swapping of register sets within&#xD;
    the CPU (&lt;b>context switching&lt;/b>) that even with modern high-speed processors may take hundreds of microseconds.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    To reduce this overhead, many operating systems provide the ability to include multiple &lt;b>lightweight threads&lt;/b>&#xD;
    within a single process. The threads within a process share the address space of that process. This reduces the&#xD;
    overhead involved in context switching, but increases the likelihood of memory conflicts.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    For some high-throughput applications, even the overhead of lightweight thread switching may be unacceptably high. In&#xD;
    such situations it is common to have an even lighter-weight form of multi-tasking that is achieved by taking advantage&#xD;
    of some special features of the application.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The concurrency requirements of the system can have a dramatic impact upon the architecture of the system. The decision&#xD;
    to move functionality from a uni-process architecture to a multi-process architecture introduces significant changes to&#xD;
    the structure of the system, in many dimensions. Additional mechanisms (e.g. remote procedure calls) may need to be&#xD;
    introduced which may substantially change the architecture of the system.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    System availability requirements must be considered, as well as the additional overhead of managing the additional&#xD;
    processes and threads.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    As with most architectural decisions, changing the process architecture effectively trades one set of problems for&#xD;
    another:&#xD;
&lt;/p>&#xD;
&lt;div align=&quot;center&quot;>&#xD;
    &lt;table&#xD;
    style=&quot;BORDER-RIGHT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-BOTTOM: rgb(128,128,128) 1px solid&quot;&#xD;
     cellspacing=&quot;0&quot; bordercolordark=&quot;#808080&quot; cellpadding=&quot;4&quot; width=&quot;85%&quot; bordercolorlight=&quot;#808080&quot; border=&quot;1&quot;>&#xD;
        &lt;tbody>&#xD;
            &lt;tr>&#xD;
                &lt;th scope=&quot;col&quot; width=&quot;18%&quot;>&#xD;
                    &lt;p class=&quot;tableheading&quot;>&#xD;
                        Approach&#xD;
                    &lt;/p>&#xD;
                &lt;/th>&#xD;
                &lt;th scope=&quot;col&quot; width=&quot;46%&quot;>&#xD;
                    &lt;p class=&quot;tableheading&quot;>&#xD;
                        Advantages&#xD;
                    &lt;/p>&#xD;
                &lt;/th>&#xD;
                &lt;th scope=&quot;col&quot; width=&quot;46%&quot;>&#xD;
                    &lt;p class=&quot;tableheading&quot;>&#xD;
                        Disadvantages&#xD;
                    &lt;/p>&#xD;
                &lt;/th>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;18%&quot;>&#xD;
                    Uni-process, no threads&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;46%&quot;>&#xD;
                    &lt;ul>&#xD;
                        &lt;li>&#xD;
                            Simplicity&#xD;
                        &lt;/li>&#xD;
                        &lt;li>&#xD;
                            Fast intra-process messaging&#xD;
                        &lt;/li>&#xD;
                    &lt;/ul>&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;46%&quot;>&#xD;
                    &lt;ul>&#xD;
                        &lt;li>&#xD;
                            Hard to balance workload&#xD;
                        &lt;/li>&#xD;
                        &lt;li>&#xD;
                            Can't scale to multiple processors&#xD;
                        &lt;/li>&#xD;
                    &lt;/ul>&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;18%&quot;>&#xD;
                    Uni-process, multi-threaded&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;46%&quot;>&#xD;
                    &lt;ul>&#xD;
                        &lt;li>&#xD;
                            Fast intra-process messages&#xD;
                        &lt;/li>&#xD;
                        &lt;li>&#xD;
                            Multi-tasking without inter-process communication&#xD;
                        &lt;/li>&#xD;
                        &lt;li>&#xD;
                            Better multi-tasking without the overhead of 'heavyweight' processes&#xD;
                        &lt;/li>&#xD;
                    &lt;/ul>&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;46%&quot;>&#xD;
                    &lt;ul>&#xD;
                        &lt;li>&#xD;
                            Application must be 'thread-safe'&#xD;
                        &lt;/li>&#xD;
                        &lt;li>&#xD;
                            Operating system must have efficient thread-management&#xD;
                        &lt;/li>&#xD;
                        &lt;li>&#xD;
                            Shared memory issues need to be considered&#xD;
                        &lt;/li>&#xD;
                    &lt;/ul>&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;18%&quot;>&#xD;
                    Multi-process&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;46%&quot;>&#xD;
                    &lt;ul>&#xD;
                        &lt;li>&#xD;
                            Scales well as processors are added&#xD;
                        &lt;/li>&#xD;
                        &lt;li>&#xD;
                            Relatively easy to distribute across nodes&#xD;
                        &lt;/li>&#xD;
                    &lt;/ul>&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;46%&quot;>&#xD;
                    &lt;ul>&#xD;
                        &lt;li>&#xD;
                            Sensitive to process boundary: using inter-process communication too much hurts performance&#xD;
                        &lt;/li>&#xD;
                        &lt;li>&#xD;
                            Swapping and context switches are expensive&#xD;
                        &lt;/li>&#xD;
                        &lt;li>&#xD;
                            Harder to design&#xD;
                        &lt;/li>&#xD;
                    &lt;/ul>&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
        &lt;/tbody>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    A typical evolutionary path is to start with a uni-process architecture, adding processes for groups of behaviors that&#xD;
    need to occur simultaneously. Within these broader groupings, consider additional needs for concurrency, adding threads&#xD;
    within processes to increase concurrency.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The initial starting point is to assign many active objects to a single operating system task or thread, using a&#xD;
    purpose-built active object scheduler - this way it is usually possible to achieve a very lightweight simulation of&#xD;
    concurrency, although, with a single operating system task or thread, it will not be possible to take advantage of&#xD;
    machines with multiple CPUs.&amp;nbsp; The key decision is to isolate blocking behavior in separate threads, so that&#xD;
    blocking behavior does not become a bottleneck. This will result in a separation of active objects with blocking&#xD;
    behavior into their own operating system threads.&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;reactive&quot;>&#xD;
    In real-time systems, this reasoning applies equally to capsules - each capsule has a logical thread of control, which&#xD;
    may or may not share an operating system thread, task or process with other capsules.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;Issues&quot; name=&quot;Issues&quot;>Issues&lt;/a>&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Unfortunately, like many architectural decisions, there are no easy answers; the right solution involves a carefully&#xD;
    balanced approach. Small architectural prototypes can be used to explore the implications of a particular set of&#xD;
    choices. In prototyping the process architecture, focus on scaling the number of processes up to the theoretical&#xD;
    maximums for the system. Consider the following issues:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Can the number of processes be scaled up to the maximum? How far beyond the maximum can the system be pushed? Is&#xD;
        there allowance for potential growth?&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        What is the impact of changing some of the processes to lightweight threads which operate in a shared process&#xD;
        address space?&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        What happens to response time as the number of processes are added? As the amount of inter-process communication&#xD;
        (IPC) is increased? Is there noticeable degradation?&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Could the amount of IPC be reduced by combining or reorganizing processes? Would such a change result in large&#xD;
        monolithic processes which are difficult to load-balance?&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Can shared memory be used to reduce IPC?&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Should all processes get &quot;equal time&quot; when time resources are allocated? Is it possible to carry the time&#xD;
        allocation? Are there potential draw-backs to changing the scheduling priorities?&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h4>&#xD;
    &lt;font size=&quot;+0&quot;>&lt;b>&lt;a id=&quot;Inter-Object Communications&quot; name=&quot;Inter-Object Communications&quot;>Inter-Object&#xD;
    Communications&lt;/a>&lt;/b>&lt;/font>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Active objects can communicate with each other synchronously or asynchronously. Synchronous communication is useful&#xD;
    because it can simplify complex collaborations through strictly controlled sequencing. That is, while an active object&#xD;
    is executing a run-to-completion step that involves synchronous invocations of other active objects, any concurrent&#xD;
    interactions initiated by other objects can be ignored until the full sequence is completed.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    While this is useful in some cases, it can also be problematic since it can happen that a more important high-priority&#xD;
    event may have to wait (priority inversion). This is exacerbated by the possibility that the synchronously invoked&#xD;
    object may itself be blocked waiting on a response to a synchronous invocation of its own. This can lead to unbounded&#xD;
    priority inversion. In the most extreme case, if there is circularity in the chain of synchronous invocations, it can&#xD;
    lead to deadlock.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Asynchronous invocations avoid this problem enabling bounded response times. However, depending on the software&#xD;
    architecture, asynchronous communication often leads to more complex code since an active object may have to respond to&#xD;
    several asynchronous events (each of which might entail a complex sequence of asynchronous interactions with other&#xD;
    active objects) at any time. This can be very difficult and error prone to implement.&amp;nbsp;&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The use of an asynchronous messaging technology with assured message delivery can simplify the application programming&#xD;
    task. The application can continue operation even if the network connection or remote application is unavailable.&#xD;
    Asynchronous messaging does not preclude using it in a synchronous mode. Synchronous technology will require a&#xD;
    connection to be available whenever the application is available. Because a connection is known to exist, handling&#xD;
    commit processing may be easier.&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;reactive&quot;>&#xD;
    In the approach recommended in the Rational Unified Process for real-time systems, &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../core.base_rup/workproducts/rup_capsule_FC4A34FD.html&quot; guid=&quot;{4423FCE1-FF59-4C8E-A6C4-AA4B13CB3250}&quot;>capsules&lt;/a>&#xD;
    communicate asynchronously through the use of &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../core.base_rup/workproducts/rup_signal_AD16C912.html&quot; guid=&quot;{8CA124DA-A80C-45D7-BC65-BA6B4247FF11}&quot;>signals&lt;/a>,&#xD;
    according to particular &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../core.base_rup/workproducts/rup_protocol_BEB5FBE1.html&quot;&#xD;
    guid=&quot;{6E4F4D6F-2934-432C-9335-5537B795F67F}&quot;>protocols&lt;/a>. It is possible, nevertheless to achieve synchronous&#xD;
    communication through the use of signal pairs, one in each direction.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;font size=&quot;+0&quot;>&lt;b>&lt;a id=&quot;Pragmatics&quot; name=&quot;Pragmatics&quot;>Pragmatics&lt;/a>&lt;/b>&lt;/font>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Although the context-switching overhead of active objects may be very low, it is possible that some applications may&#xD;
    still find that cost unacceptable. This typically occurs in situations where large amounts of data need to be processed&#xD;
    at a high rate. In those cases, we may have to fall back to using passive objects and more traditional (but higher&#xD;
    risk) concurrency management techniques such as semaphores.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    These considerations, however, do not necessarily imply that we must abandon the active object approach altogether.&#xD;
    Even in such data-intensive applications, it is often the case that the performance sensitive part is a relatively&#xD;
    small portion of the overall system. This implies that the rest of the system can still take advantage of the active&#xD;
    object paradigm.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    In general, performance is only one of the design criteria when it comes to system design. If the system is complex,&#xD;
    then other criteria such as maintainability, ease of change, understandability, etc. are equally if not even more&#xD;
    important. The active object approach has a clear advantage since it hides much of the complexity of concurrency and&#xD;
    concurrency management while allowing design to be expressed in application-specific terms as opposed to low-level&#xD;
    technology-specific mechanisms.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;Heuristics&quot; name=&quot;Heuristics&quot;>Heuristics&lt;/a>&#xD;
&lt;/h3>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;Focus on interactions&quot; name=&quot;Focus on interactions&quot;>Focus on Interactions between Concurrent Components&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Concurrent components with no interactions are an almost trivial problem. Nearly all of the design challenges have to&#xD;
    do with interactions among concurrent tasks, so we must first focus our energy on understanding the interactions. Some&#xD;
    of the questions to ask are:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Is the interaction one-directional, bi-directional, or multi-directional?&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Is there a client-server or master slave relationship?&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Is some form of synchronization required?&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    Once the interaction is understood, we can think about ways to implement it. The implementation should be selected to&#xD;
    yield the simplest design consistent with the performance goals of the system. Performance requirements generally&#xD;
    include both overall throughput and acceptable latency in the response to externally generated events.&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;reactive&quot;>&#xD;
    These issues are even more critical for real-time systems, which are often less tolerant of variations in performance,&#xD;
    for example 'jitter' in response time, or missed deadlines.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;Isolate and encapsulate external interfaces.&quot; name=&quot;Isolate and encapsulate external interfaces.&quot;>Isolate and&#xD;
    Encapsulate External Interfaces&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    It is bad practice to embed specific assumptions about external interfaces throughout an application, and it is very&#xD;
    inefficient to have several threads of control blocked waiting for an event. Instead, assign a single object the&#xD;
    dedicated task of detecting the event. When the event occurs, that object can notify any others who need to know about&#xD;
    the event. This design is based upon a well-known and proven design pattern, the &quot;Observer&quot; pattern [&lt;a&#xD;
    class=&quot;elementLinkWithUserText&quot; href=&quot;./../../../core.base_rup/customcategories/references_56F06DFD.html&quot;&#xD;
    guid=&quot;7.755968586980351E-308&quot;>GAM94&lt;/a>]. It can easily be extended for even greater flexibility to the&#xD;
    &quot;Publisher-Subscriber Pattern,&quot; where a publisher object acts as intermediary between the event detectors and the&#xD;
    objects interested in the event (&quot;subscribers&quot;) [&lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../core.base_rup/customcategories/references_56F06DFD.html&quot; guid=&quot;7.755968586980351E-308&quot;>BUS96&lt;/a>].&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;Isolate and encapsulate blocking and polling behavior.&quot;&#xD;
    name=&quot;Isolate and encapsulate blocking and polling behavior.&quot;>Isolate and Encapsulate Blocking and Polling Behavior&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Actions in a system may be triggered by the occurrence of externally generated events. One very important externally&#xD;
    generated event may be simply the passage of time itself, as represented by the tick of a clock. Other external events&#xD;
    come from input devices connected to external hardware, including user interface devices, process sensors, and&#xD;
    communication links to other systems. This is overwhelmingly true for real-time systems, which typically have high&#xD;
    connectivity with the outside world.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    In order for software to detect an event, it must be either blocked waiting for an interrupt, or periodically checking&#xD;
    hardware to see if the event has occurred. In the latter case, the periodic cycle may need to be short to avoid missing&#xD;
    a short lived event or multiple occurrences, or simply to minimize the latency between the event's occurrence and&#xD;
    detection.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The interesting thing about this is that no matter how rare an event is, some software must be blocked waiting for it&#xD;
    or frequently checking for it. But many (if not most) of the events a system must handle are rare; most of the time, in&#xD;
    any given system, nothing of any significance is happening.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The elevator system provides many good examples of this. Important events in the life of an elevator include a call for&#xD;
    service, passenger floor selection, a passenger's hand blocking the door, and passing from one floor to the next. Some&#xD;
    of these events require very time-critical response, but all are extremely rare compared to the time-scale of the&#xD;
    desired response time.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    A single event may trigger many actions, and the actions may depend upon the states of various objects. Furthermore,&#xD;
    different configurations of a system may use the same event differently. For example, when an elevator passes a floor&#xD;
    the display in the elevator cab should be updated and the elevator itself must know where it is so that it knows how to&#xD;
    respond to new calls and passenger floor selections. There may or may not be elevator location displays at each floor.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;Prefer reactive behavior to scheduled behavior.&quot; name=&quot;Prefer reactive behavior to scheduled behavior.&quot;>Prefer&#xD;
    Reactive Behavior to Polling Behavior&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Polling is expensive; it requires some part of the system to periodically stop what it is doing to check to see if an&#xD;
    event has occurred. If the event must be responded to quickly, the system will have to check for event arrival quite&#xD;
    frequently, further limiting the amount of other work which can be accomplished.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    It is far more efficient to allocate an interrupt to the event, with the event-dependent code being activated by the&#xD;
    interrupt. Though interrupts are sometimes avoided because they are considered &quot;expensive&quot;, using interrupts&#xD;
    judiciously can be far more efficient than repeated polling.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Cases where interrupts would be preferred as an event-notification mechanism are those where event arrival is random&#xD;
    and infrequent, such that most polling efforts find that the event had not occurred. Cases where polling would be&#xD;
    preferred are those in which events arrive in a regular and predictable manner and most polling efforts find that the&#xD;
    event has occurred. In the middle, there will be a point at which one is indifferent to either polling or reactive&#xD;
    behavior - either will do equally well and the choice matters little. In most cases, however, given the randomness of&#xD;
    events in the real world, reactive behavior is preferred.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;Prefer event notification to data broadcasting&quot; name=&quot;Prefer event notification to data broadcasting&quot;>Prefer&#xD;
    Event Notification to Data Broadcasting&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Broadcasting data (typically using signals) is expensive, and is typically wasteful - only a few objects may be&#xD;
    interested in the data, but everyone (or many) must stop to examine it. A better, less resource consumptive approach is&#xD;
    to use notification to inform only those objects who are interested that some event has occurred. Restrict broadcasting&#xD;
    to events which require the attention of many objects (typically timing or synchronization events).&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;Make heavy use of light-weight mechanisms and light use of heavy-weight mechanisms.&quot;&#xD;
    name=&quot;Make heavy use of light-weight mechanisms and light use of heavy-weight mechanisms.&quot;>Make Heavy Use of&#xD;
    Light-weight Mechanisms and Light Use of Heavy-weight Mechanisms&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    More specifically:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Use passive objects and synchronous method invocations where concurrency is not an issue but instantaneous response&#xD;
        is.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Use active objects and asynchronous messages for the vast majority of application-level concurrency concepts.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Use OS threads to isolate blocking elements. An active object can be mapped to an OS thread.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Use OS processes for maximum isolation. Separate processes are needed if programs need to be started up and shut&#xD;
        down independently, and for subsystems which may need to be distributed.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Use separate CPUs for physical distribution or for raw horsepower.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    Perhaps the most important guideline for developing efficient concurrent applications is to maximize the use of the&#xD;
    lightest weight concurrency mechanisms. Both hardware and operating system software play a major part in supporting&#xD;
    concurrency, but both provide relatively heavy-weight mechanisms, leaving a great deal of work to the application&#xD;
    designer. We are left to bridge a big gap between the available tools and the needs of concurrent applications.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Active objects help to bridge this gap by virtue of two key features:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        They unify the design abstractions by encapsulating the basic unit of concurrency (a thread of control) which can&#xD;
        be implemented using any of the underlying mechanisms provided by the OS or CPU.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        When active objects share a single OS thread, they become a very efficient, light-weight concurrency mechanism&#xD;
        which would otherwise have to be implemented directly in the application.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    Active objects also make an ideal environment for the passive objects provided by programming languages. Designing a&#xD;
    system entirely from a foundation of concurrent objects without procedural artifacts like programs and processes leads&#xD;
    to more modular, cohesive, and understandable designs.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;Eschew performance bigotry.&quot; name=&quot;Eschew performance bigotry.&quot;>Eschew performance bigotry&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    In most systems less than 10% of the code uses more than 90% of the CPU cycles.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Many system designers act as though every line of code must be optimized. Instead, spend your time optimizing the 10%&#xD;
    of the code that runs most often or takes a long time. Design the other 90% with an emphasis on understandability,&#xD;
    maintainability, modularity, and ease of implementation.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;Choosing Mechanisms&quot; name=&quot;Choosing Mechanisms&quot;>Choosing Mechanisms&lt;/a>&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    The non-functional requirements and the architecture of the system will affect the choice of mechanisms used to&#xD;
    implement remote procedure calls.&amp;nbsp; An overview of the kinds of trade-offs between alternatives is presented&#xD;
    below.&amp;nbsp;&#xD;
&lt;/p>&#xD;
&lt;div align=&quot;center&quot;>&#xD;
    &lt;table&#xD;
    style=&quot;BORDER-RIGHT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-BOTTOM: rgb(128,128,128) 1px solid&quot;&#xD;
     cellspacing=&quot;0&quot; bordercolordark=&quot;#808080&quot; cellpadding=&quot;4&quot; width=&quot;85%&quot; bordercolorlight=&quot;#808080&quot; border=&quot;1&quot;>&#xD;
        &lt;tbody>&#xD;
            &lt;tr>&#xD;
                &lt;th scope=&quot;col&quot; width=&quot;20%&quot;>&#xD;
                    Mechanism&#xD;
                &lt;/th>&#xD;
                &lt;th scope=&quot;col&quot; width=&quot;26%&quot;>&#xD;
                    Uses&#xD;
                &lt;/th>&#xD;
                &lt;th scope=&quot;col&quot; width=&quot;54%&quot;>&#xD;
                    Comments&#xD;
                &lt;/th>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;20%&quot;>&#xD;
                    Messaging&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;26%&quot;>&#xD;
                    Asynchronous access to enterprise servers&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;54%&quot;>&#xD;
                    Messaging middleware can simplify the application programming task by handling queuing, timeout and&#xD;
                    recovery/restart conditions. You can also use messaging middleware in a pseudo-synchronous mode.&#xD;
                    Typically, messaging technology can support large message sizes. Some RPC approaches may be limited in&#xD;
                    message sizes, requiring additional programming to handle large messages.&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;20%&quot;>&#xD;
                    JDBC/ODBC&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;26%&quot;>&#xD;
                    Database calls&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;54%&quot;>&#xD;
                    These are database-independent interfaces for Java servlets or application programs to make calls to&#xD;
                    databases that may be on the same or another server.&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;20%&quot;>&#xD;
                    Native interfaces&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;26%&quot;>&#xD;
                    Database calls&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;54%&quot;>&#xD;
                    Many database vendors have implemented native application program interfaces to their own databases&#xD;
                    which offer a performance advantage over ODBC at the expense of application portability.&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;20%&quot;>&#xD;
                    Remote Procedure Call&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;26%&quot;>&#xD;
                    To call programs on remote servers&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;54%&quot;>&#xD;
                    You may not need to program at the RPC level if you have an application builder that takes care of this&#xD;
                    for you.&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;20%&quot;>&#xD;
                    Conversational&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;26%&quot;>&#xD;
                    Little used in e-business applications&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;54%&quot;>&#xD;
                    Typically low-level program-to-program communication using protocols such as APPC or Sockets.&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
        &lt;/tbody>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;Summary&quot; name=&quot;Summary&quot;>Summary&lt;/a>&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Many systems require concurrent behavior and distributed components. Most programming languages give us very little&#xD;
    help with either of these issues. We have seen that we need good abstractions to understand both the need for&#xD;
    concurrency in applications, and the options for implementing it in software. We have also seen that, paradoxically,&#xD;
    while concurrent software is inherently more complex than non-concurrent software, it is also capable of vastly&#xD;
    simplifying the design of systems which must deal with concurrency in the real world.&#xD;
&lt;/p>&lt;br />&#xD;
&lt;br /></mainDescription>
</org.eclipse.epf.uma:ContentDescription>
