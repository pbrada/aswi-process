<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:TaskDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmi:id="_2jFNtNnmEdmO6L4XMImrsA" name="implement_test,{BC805E79-736B-42D5-BDC1-B95E7D002312}" guid="_2jFNtNnmEdmO6L4XMImrsA" changeDate="2005-11-04T07:49:11.471-0800" version="7.1.0">
  <sections xmi:id="_WPJ94NnnEdmO6L4XMImrsA" name=" Select appropriate implementation technique " guid="_WPJ94NnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;SelectImplementTechnique&quot; name=&quot;SelectImplementTechnique&quot;>&lt;/a> &#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table&#xD;
    style=&quot;BORDER-RIGHT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-BOTTOM: rgb(128,128,128) 1px solid&quot;&#xD;
     cellspacing=&quot;0&quot; bordercolordark=&quot;#808080&quot; cellpadding=&quot;4&quot; width=&quot;100%&quot; bordercolorlight=&quot;#808080&quot; border=&quot;1&quot;>&#xD;
        &lt;tbody>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;5%&quot;>&#xD;
                    &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;95%&quot;>&#xD;
                    To determine the appropriate technique to implement the test.&amp;nbsp;&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
        &lt;/tbody>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Select the most appropriate technique to implement the test. For each test that you want to conduct, consider&#xD;
    implementing at least one Test Script. In some instances, the implementation for a given test will span multiple Test&#xD;
    Scripts. In others, a single Test Script will provide the implementation for multiple tests.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Typical methods for implementing tests include writing a textual description in the form of a script to be followed&#xD;
    (for manual testing) and the programming, captured-recording or generation of a script-based programming language (for&#xD;
    automated testing). Each method is discussed in the following sections.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    As with most approaches, we recommend you'll get more useful results if you use a mixture of the following techniques.&#xD;
    While you don't need to use them all, you shouldn't confine yourself to using a single technique either.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;b>Sub-topics:&lt;/b>&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#ManualTestScripts&quot;>Manual Test Scripts&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#ProgramTestScripts&quot;>Programmed Test Scripts&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#RecordTestScripts&quot;>Recorded or captured Test Scripts&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#GenerateTests&quot;>Generated Tests&lt;/a>&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;ManualTestScripts&quot; name=&quot;ManualTestScripts&quot;>Manual Test Scripts&lt;/a> &lt;a href=&quot;#SelectImplementTechnique&quot;>&lt;img&#xD;
    height=&quot;20&quot; alt=&quot;To Select Implement Technique&quot; src=&quot;./../../core.base_rup/resources/top.gif&quot; width=&quot;26&quot; border=&quot;0&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Many tests are best conducted manually, and you should avoid the trap of attempting to inappropriately automate tests.&#xD;
    Usability tests are an area where manual testing is in many cases a better solution than an automated one. Also tests&#xD;
    that require validation of the accuracy and quality of the physical outputs from a software system generally require&#xD;
    manual validation. As a general heuristic, it's a good idea to begin the first tests of a particular Target Test Item&#xD;
    with a manual implementation; this approach allows the tester to learn about the target item, adapt to unexpected&#xD;
    behavior from it, and apply human judgment to determine the next appropriate action to be taken.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Sometimes manually conducted tests will be subsequently automated and reused as part of a regression testing strategy.&#xD;
    Note however that it isn't necessary or desirable-or even possible-to automate every test that you could otherwise&#xD;
    conduct manually. Automation brings certain advantages in speed and accuracy of test execution, visibility and&#xD;
    collation of detailed test results and in efficiency of creating and maintaining complex tests, but like all useful&#xD;
    tools, it isn't the solution to all your needs.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Automation comes with certain disadvantages: these basically amount to an absence of human judgment and reasoning&#xD;
    during test execution. The automation solutions currently available simply don't have the cognitive abilities that a&#xD;
    human does-and it's arguably unlikely that they ever will. During implementation of a manual test, human reasoning can&#xD;
    be applied to the observed responses of the system to stimulus. Current automated test techniques and their supporting&#xD;
    tools typically have limited ability to notice the implications of certain system behaviors, and have minimal ability&#xD;
    to infer possible problems through deductive reasoning.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;ProgramTestScripts&quot; name=&quot;ProgramTestScripts&quot;>Programmed Test Scripts&lt;/a> &lt;a&#xD;
    href=&quot;#SelectImplementTechnique&quot;>&lt;img height=&quot;20&quot; alt=&quot;To Select Implement Technique&quot;&#xD;
    src=&quot;./../../core.base_rup/resources/top.gif&quot; width=&quot;26&quot; border=&quot;0&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Arguably the method of choice practiced by most testers who use test automation. In it's purest form, this practice is&#xD;
    performed in the same manner and using the same general principles as software programming. As such, most methods and&#xD;
    tools used for software programming are generally applicable and useful to test automation programming.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Using either a standard software development environment (such as Microsoft Visual Studio or IBM Visual Age) or a&#xD;
    specialized test automation development environment (such as the IDE provided with Rational Robot), the tester is free&#xD;
    to harness the features and power of the development environment to best effect.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The negative aspects of programming automated tests are related to the negative aspects of programming itself as a&#xD;
    general technique. For programming to be effective, some consideration should be given to appropriate design: without&#xD;
    this the implementation will likely fail. If the developed software will likely be modified by different people over&#xD;
    time-the usual situation-then some consideration must be given to adopting a common style and form to be used in&#xD;
    program development, and ensuring it's correct use. Arguably the two most important concerns relate to the misuse of&#xD;
    this technique.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    First, there is a risk that a tester will become engrossed in the features of the programming environment, and spend&#xD;
    too much time crafting elegant and sophisticated solutions to problems that could be achieved by simpler means. The&#xD;
    result is that the tester wastes precious time on what are essentially programming tasks to the detriment of time that&#xD;
    could be spent actually testing and evaluating the Target Test Items. It requires both discipline and experience to&#xD;
    avoid this pitfall.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Secondly, there is the risk that the program code used to implement the test will itself have bugs introduced through&#xD;
    human error or omission. Some of these bugs will be easy to debug and correct in the natural course of implementing the&#xD;
    automated test: others won't. Just as errors can be elusive to detect in the Target Test Item, it can be equally&#xD;
    difficult to detect errors in test automation software. Furthermore, errors may be introduced where algorithms used in&#xD;
    the automated test implementation are based on the same faulty algorithms used by the software implementation itself.&#xD;
    This results in errors going undetected, hidden by the false security of automated tests that apparently execute&#xD;
    successfully. Mitigate this risk by using different algorithms in the automated tests wherever possible.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;RecordTestScripts&quot; name=&quot;RecordTestScripts&quot;>Recorded or captured Test Scripts&lt;/a> &lt;a&#xD;
    href=&quot;#SelectImplementTechnique&quot;>&lt;img height=&quot;20&quot; alt=&quot;To Select Implement Technique&quot;&#xD;
    src=&quot;./../../core.base_rup/resources/top.gif&quot; width=&quot;26&quot; border=&quot;0&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    There are a number of test automation tools that provide the ability to record or capture human interaction with a&#xD;
    software application and produce a basic Test Script. There are a number of different tool solutions for this. Most&#xD;
    tools produce a Test Script implemented in some form of a high-level, normally editable, programming language. The most&#xD;
    common designs work in one of the following ways:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Capturing the interaction with the client &lt;a class=&quot;elementLink&quot;&#xD;
        href=&quot;./../../core.base_rup/guidances/termdefinitions/ui_929A0D03.html&quot; guid=&quot;_yZZbg9nmEdmO6L4XMImrsA&quot;>UI&lt;/a>&amp;nbsp;of an&#xD;
        application based on intercepting the inputs sent from the client hardware peripheral input devices: mouse,&#xD;
        keyboard and so forth to the client operating system. In some solutions, this is done by intercepting high-level&#xD;
        messages exchanged between the operating system and the device driver that describe the interactions in a somewhat&#xD;
        meaningful way; in other solutions this is done by capturing low-level messages, often based at the level of&#xD;
        time-based movements in mouse coordinates or key-up and key-down events.&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Intercepting the messages sent and received across the network between the client application and one or more&#xD;
        server applications. The successful interpretation of those messages relies typically on the use of standard,&#xD;
        recognized messaging protocols, such as &lt;a class=&quot;elementLink&quot;&#xD;
        href=&quot;./../../core.base_rup/guidances/termdefinitions/http_17BB6CED.html&quot; guid=&quot;_yKCw5tnmEdmO6L4XMImrsA&quot;>HTTP&lt;/a>, &lt;a&#xD;
        class=&quot;elementLink&quot; href=&quot;./../../core.base_rup/guidances/termdefinitions/sql_E258F221.html&quot;&#xD;
        guid=&quot;_yV9tCdnmEdmO6L4XMImrsA&quot;>SQL&lt;/a>&amp;nbsp;and so forth. Some tools also allow the capture of &quot;base&quot;&#xD;
        communications protocols such as &lt;a class=&quot;elementLink&quot;&#xD;
        href=&quot;./../../core.base_rup/guidances/termdefinitions/tcp_ip_CE2F490E.html&quot; guid=&quot;_yXmrw9nmEdmO6L4XMImrsA&quot;>TCP/IP&lt;/a>,&#xD;
        however it can be more complex to work with Test Scripts of this nature.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    While these techniques are generally useful to include as part of your approach to automated testing, some&#xD;
    practitioners feel these techniques have limitations. One of the main concerns is that some tools simply capture&#xD;
    application interaction and do nothing else. Without the additional inclusion of observation points that capture and&#xD;
    compare system state during subsequent script execution, the basic Test Script cannot be considered to be a&#xD;
    fully-formed test. Where this is the case, the initial recording will need to be subsequently augmented with additional&#xD;
    custom program code to implement observation points within the Test Script.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Various authors have published books and essays on this and other concerns related to using test procedure record or&#xD;
    capture as a test automation technique. To gain a more in-depth understanding of these issues, we recommend reviewing&#xD;
    the work available on the Internet by the following authors: &lt;a href=&quot;http://www.satisfice.com/&quot; target=&quot;_blank&quot;>James&#xD;
    Bach&lt;/a>, &lt;a href=&quot;http://www.kaner.com/articles.html&quot; target=&quot;_blank&quot;>Cem Kaner&lt;/a>, &lt;a&#xD;
    href=&quot;http://www.testing.com/writings.html&quot; target=&quot;_blank&quot;>Brian Marick&lt;/a> and &lt;a&#xD;
    href=&quot;http://www.io.com/~wazmo/papers/&quot; target=&quot;_blank&quot;>Bret Pettichord&lt;/a>, and the relevant content in the book&#xD;
    &lt;i>Lessons Learned in Software Testing&lt;/i> &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../core.base_rup/customcategories/references_56F06DFD.html#KAN01&quot; guid=&quot;7.755968586980351E-308&quot;>[KAN01]&lt;/a>&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;GenerateTests&quot; name=&quot;GenerateTests&quot;>Generated Tests&lt;/a> &lt;a href=&quot;#SelectImplementTechnique&quot;>&lt;img height=&quot;20&quot;&#xD;
    alt=&quot;To Select Implement Technique&quot; src=&quot;./../../core.base_rup/resources/top.gif&quot; width=&quot;26&quot; border=&quot;0&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Some of the more sophisticated test automation software enables the actual generation of various aspects of the&#xD;
    test-either the procedural aspects or the Test Data aspects of the Test Script-based on generation algorithms. This&#xD;
    type of automation can play a useful part in your test effort, but shouldn't be considered a sufficient approach by&#xD;
    itself. The Rational TestFactory tool and the Rational TestManager datapool generation feature are example&#xD;
    implementations of this type of technology.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_WRF3kNnnEdmO6L4XMImrsA" name=" Set up test environment preconditions " guid="_WRF3kNnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;Setup&quot; name=&quot;Setup&quot;>&lt;/a> &#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table&#xD;
    style=&quot;BORDER-RIGHT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-BOTTOM: rgb(128,128,128) 1px solid&quot;&#xD;
     cellspacing=&quot;0&quot; bordercolordark=&quot;#808080&quot; cellpadding=&quot;4&quot; width=&quot;100%&quot; bordercolorlight=&quot;#808080&quot; border=&quot;1&quot;>&#xD;
        &lt;tbody>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;5%&quot;>&#xD;
                    &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;95%&quot;>&#xD;
                    To ready the environment to the correct starting state.&amp;nbsp;&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
        &lt;/tbody>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Setup the test environment, including all hardware, software, tools, and data. Ensure all components are functioning&#xD;
    properly. Typically this will involve some form of basic environment reset (e.g. resetting the &lt;a class=&quot;elementLink&quot;&#xD;
    href=&quot;./../../core.base_rup/guidances/termdefinitions/windows_registry_2A6006F9.html&quot; guid=&quot;_ycE8E9nmEdmO6L4XMImrsA&quot;>windows&#xD;
    registry&lt;/a>&amp;nbsp;and other configuration files), restoration of underlying databases to known state, and so forth in&#xD;
    addition to tasks such as loading paper into printers. While some tasks can be performed automatically, some aspects&#xD;
    typically require human attention.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;b>Sub-topics:&lt;/b>&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#ManualCheck&quot;>(Optional) Manual walk-through of the test&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#ConfirmTestOracles&quot;>Identify and confirm appropriateness of Test Oracles&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#ResetEnvTools&quot;>Reset test environment and tools&lt;/a>&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;ManualCheck&quot; name=&quot;ManualCheck&quot;>(Optional) Manual walk-through of the test&lt;/a> &lt;a href=&quot;#Setup&quot;>&lt;img height=&quot;20&quot;&#xD;
    alt=&quot;To Setup&quot; src=&quot;./../../core.base_rup/resources/top.gif&quot; width=&quot;26&quot; border=&quot;0&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Especially applicable to automated Test Scripts, it can be beneficial to initially walk-through the test manually to&#xD;
    confirm expected prerequisites are present. During the walk-through, you should verify the integrity of the&#xD;
    environment, the software and the test design. The walk-through is most relevant where you are using an interactive&#xD;
    recording technique, and least relevant where you are programming the Test Script. The objective is to verify that all&#xD;
    the elements required to implement the test successfully are present.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Where the software is known to be sufficiently stable or mature, you way elect to skip this step where you deem the&#xD;
    risk of problems occurring in the areas the manual walk-through addresses are relatively low.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;ConfirmTestOracles&quot; name=&quot;ConfirmTestOracles&quot;>Identify and confirm appropriateness of Test Oracles&lt;/a> &lt;a&#xD;
    href=&quot;#Setup&quot;>&lt;img height=&quot;20&quot; alt=&quot;To Setup&quot; src=&quot;./../../core.base_rup/resources/top.gif&quot; width=&quot;26&quot; border=&quot;0&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Confirm that the &lt;a class=&quot;elementLink&quot; href=&quot;./../../core.base_rup/guidances/termdefinitions/test_oracle_CB9E18A9.html&quot;&#xD;
    guid=&quot;_yYNIs9nmEdmO6L4XMImrsA&quot;>test oracle&lt;/a>s&amp;nbsp;you plan to use are appropriate. Where they have not already been&#xD;
    identified, now is the time for you to do so.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    You should try to confirm through alternative means that the chosen Test Oracle(s) will provide accurate and reliable&#xD;
    results. For example, if you plan to validate test results using a field displayed via the application's UI that&#xD;
    indicates a database update has occurred, consider independently querying the back-end database to verify the state of&#xD;
    the corresponding records in the database. Alternatively, you might ignore the results presented in an update&#xD;
    confirmation dialog, and instead confirm the update by querying for the record through an alternative front-end&#xD;
    function or operation.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;ResetEnvTools&quot; name=&quot;ResetEnvTools&quot;>Reset test environment and tools&lt;/a> &lt;a href=&quot;#Setup&quot;>&lt;img height=&quot;20&quot;&#xD;
    alt=&quot;To Setup&quot; src=&quot;./../../core.base_rup/resources/top.gif&quot; width=&quot;26&quot; border=&quot;0&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Next you should restore the environment-including the supporting tools-back to it's original state. As mentioned in&#xD;
    previous steps, this will typically involve some form of basic operating environment reset, restoration of underlying&#xD;
    databases to a known state, and so forth in addition to tasks such as loading paper into printers. While some reset&#xD;
    tasks can be performed automatically, some aspects typically require human attention.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Set the implementation options of the test-support tools, which will vary depending on the sophistication of the tool.&#xD;
    Where possible, you should consider storing the option settings for each tool so that they can be reloaded easily based&#xD;
    on one or more predetermined profiles. In the case of manual testing, it will include tasks such as partitioning a new&#xD;
    entry in a support system for logging the test results, or signing into an issue and change request logging system.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    In the case of automated test implementation tools, there may be many different settings to be considered. Failing to&#xD;
    set these options appropriately may reduce the usefulness and value of the resulting test assets.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_WRPokNnnEdmO6L4XMImrsA" name=" Implement the test " guid="_WRPokNnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;ImplementTest&quot; name=&quot;ImplementTest&quot;>&lt;/a> &#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table&#xD;
    style=&quot;BORDER-RIGHT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-BOTTOM: rgb(128,128,128) 1px solid&quot;&#xD;
     cellspacing=&quot;0&quot; bordercolordark=&quot;#808080&quot; cellpadding=&quot;4&quot; width=&quot;100%&quot; bordercolorlight=&quot;#808080&quot; border=&quot;1&quot;>&#xD;
        &lt;tbody>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;5%&quot;>&#xD;
                    &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;95%&quot;>&#xD;
                    To implement one or more reusable test implementation assets.&amp;nbsp;&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
        &lt;/tbody>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Using the Test-Ideas List, or one or more selected Test Case artifacts, begin to implement the test. Start by giving&#xD;
    the test a uniquely identifiable name (if it does not already have one) and prepare the IDE, capture tool, spreadsheet&#xD;
    or document to begin recording the specific steps of the test. Work through the following subsections as many times as&#xD;
    are required to implement the test.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Note that for some specific tests or types of tests, there may be little value in documenting the explicit steps&#xD;
    required to conduct the test. In certain styles of &lt;a class=&quot;elementLink&quot;&#xD;
    href=&quot;./../../core.base_rup/guidances/termdefinitions/exploratory_testing_B3C6EB1B.html&quot;&#xD;
    guid=&quot;_yItULNnmEdmO6L4XMImrsA&quot;>exploratory testing&lt;/a>&amp;nbsp;repetition of the test is not an expected deliverable. For&#xD;
    very simple tests, a brief description of the purpose of the tests will be sufficient in many cases to allow it to be&#xD;
    reproduced.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    &lt;b>Sub-topics:&lt;/b>&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#NavigationActions&quot;>Implement navigation actions&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#ObservationPoint&quot;>Implement observation points&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#ControlPoint&quot;>Implement control points&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a href=&quot;#ResolveImplementErrors&quot;>Resolve implementation errors&lt;/a>&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;NavigationActions&quot; name=&quot;NavigationActions&quot;>Implement navigation actions&lt;/a> &lt;a href=&quot;#ImplementTest&quot;>&lt;img&#xD;
    height=&quot;20&quot; alt=&quot;To top of page&quot; src=&quot;./../../core.base_rup/resources/top.gif&quot; width=&quot;26&quot; border=&quot;0&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Program, record or generate the required navigation actions. Start by selecting your appropriate navigation method of&#xD;
    choice. For most classes of system these days, a &quot;Mouse&quot; or other pointing device is the preferred and primary medium&#xD;
    for navigation. For example, the pointing and scribing device used with a Personal Digital Assistants (PDA) is&#xD;
    conceptually equivalent to a Mouse.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The secondary navigation means is generally that of keyboard interaction. In most cases, navigation will be made up of&#xD;
    a combination of mouse-driven and keyboard-driven actions.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    In some cases, you will need to consider voice-activated, light, visual and other forms of recognition. These can be&#xD;
    more troublesome to automate tests against, and may require the addition of special test-interface extensions to the&#xD;
    application to allow audio and visual elements to be loaded and processed from file rather than captured dynamically.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    In some situations, you may want to-or need to-perform the same test using multiple navigation methods. There are&#xD;
    different approaches you can take to achieve this, for example: automate all the tests using one method and manually&#xD;
    perform all or some subset of the tests using others; separate the navigation aspects of the tests from the Test Data&#xD;
    that characterize the specific test, providing and building a logical navigation interface that allows either method to&#xD;
    be selected to drive the test; simply mix and match navigation methods.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;ObservationPoint&quot; name=&quot;ObservationPoint&quot;>Implement observation points&lt;/a> &lt;a href=&quot;#ImplementTest&quot;>&lt;img&#xD;
    height=&quot;20&quot; alt=&quot;To top of page&quot; src=&quot;./../../core.base_rup/resources/top.gif&quot; width=&quot;26&quot; border=&quot;0&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    At each point in the Test Script where an observation should be taken, use the appropriate Test Oracle to capture the&#xD;
    desired information. In many cases, the information gained from the observation point will need to be recorded and&#xD;
    retained to be referenced during subsequent control points.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Where this is an automated test, decide how the observed information should be reported from the Test Script. In most&#xD;
    cases it usually appropriate simply to record the observation in a central Test Log relative to it's delta-time from&#xD;
    the start of the Test Script; in other cases specific observations might be output separately to a spreadsheet or data&#xD;
    file for more sophisticated uses.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;ControlPoint&quot; name=&quot;ControlPoint&quot;>Implement control points&lt;/a> &lt;a href=&quot;#ImplementTest&quot;>&lt;img height=&quot;20&quot;&#xD;
    alt=&quot;To top of page&quot; src=&quot;./../../core.base_rup/resources/top.gif&quot; width=&quot;26&quot; border=&quot;0&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    At each point in the Test Script where a control decision should be taken, obtain and assess the appropriate&#xD;
    information to determine the correct branch for the flow of control to follow. The data retrieved form prior&#xD;
    observation points are usually input to control points.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Where a control point occurs, and a decision made about the next action in the flow-of-control, we recommend you record&#xD;
    the input values to the control point, and the resulting flow that is selected in the Test Log.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;ResolveImplementErrors&quot; name=&quot;ResolveImplementErrors&quot;>Resolve errors in the test implementation&lt;/a> &lt;a&#xD;
    href=&quot;#ImplementTest&quot;>&lt;img height=&quot;20&quot; alt=&quot;To top of page&quot; src=&quot;./../../core.base_rup/resources/top.gif&quot; width=&quot;26&quot;&#xD;
    border=&quot;0&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    During test implementation, you'll likely introduce errors in the test implementation itself. Those errors may even be&#xD;
    the result of things you've omitted from the test implementation or may be related to things you've failed to consider&#xD;
    in the test environment. These errors will need to be resolved before the test can be considered completely&#xD;
    implemented. Identify each error you encounter and work through addressing them.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    In the case of test automation that uses a programming language, this might include compilation errors due to&#xD;
    undeclared variables and functions, or invalid use of those functions. Work your way through the error messages&#xD;
    displayed by the compiler or any other sources of error messages until the Test Script is free of syntactical and other&#xD;
    basic implementation errors.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Note that during subsequent execution of the test, other errors in the test implementation might be found. Initially&#xD;
    these may appear to be failures in the target test item - you need to be diligent when analyzing test failures that you&#xD;
    confirm the failures are actually in the target test item, and not in some aspect of the test implementation.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_WRZZkNnnEdmO6L4XMImrsA" name=" Establish external data sets " guid="_WRZZkNnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;EstablishExternalData&quot; name=&quot;EstablishExternalData&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To create and maintain data, stored externally to the test script, that are used by the test during&#xD;
                execution.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    In many cases it's more appropriate to maintain your Test Data external to the Test Script. This provides flexibility,&#xD;
    simplicity and security in Test Script and Test Data maintenance. External data sets provide value to test in the&#xD;
    following ways:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Test Data is external to the Test Script eliminating hard-coded references in the Test Script&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        External Test Data can be modified easily, usually with minimal Test Script impact&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Additional Test Cases can easily be supported by the Test Data with little or no Test Script modifications&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        External Test Data can be shared with many Test Scripts&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Test Scripts can be developed to use external Test Data to control the conditional branching logic within the Test&#xD;
        Script.&#xD;
    &lt;/li>&#xD;
&lt;/ul></sectionDescription>
  </sections>
  <sections xmi:id="_WRZZkdnnEdmO6L4XMImrsA" name=" Verify the test implementation " guid="_WRZZkdnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;VerifyTestImplementation&quot; name=&quot;VerifyTestImplementation&quot;>&lt;/a> &#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table&#xD;
    style=&quot;BORDER-RIGHT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-BOTTOM: rgb(128,128,128) 1px solid&quot;&#xD;
     cellspacing=&quot;0&quot; bordercolordark=&quot;#808080&quot; cellpadding=&quot;4&quot; width=&quot;100%&quot; bordercolorlight=&quot;#808080&quot; border=&quot;1&quot;>&#xD;
        &lt;tbody>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;5%&quot;>&#xD;
                    &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;95%&quot;>&#xD;
                    To verify the correct workings of the Test Script by executing the Test Script.&amp;nbsp;&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
        &lt;/tbody>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Especially in the case of test automation, you will probably need to spend some time stabilizing the workings of the&#xD;
    test when it is being executed. When you have completed the basic implementation of the Test Script, it should be&#xD;
    tested to ensure it implements the individual tests appropriately and that they execute properly.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;Recover&quot; name=&quot;Recover&quot;>Recover test environment to known state&lt;/a> &lt;a href=&quot;#VerifyTestImplementation&quot;>&lt;img&#xD;
    height=&quot;20&quot; alt=&quot;To Verify Test Implementation&quot; src=&quot;./../../core.base_rup/resources/top.gif&quot; width=&quot;26&quot; border=&quot;0&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Again, you should restore the environment back to it's original state, cleaning up after your test implementation work.&#xD;
    As mentioned in previous steps, this will typically involve some form of basic operating environment reset, restoration&#xD;
    of underlying databases to known state, and so forth in addition to tasks such as loading paper into printers. While&#xD;
    some tasks can be performed automatically, some aspects typically require human attention.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;SetupandPlayback&quot; name=&quot;SetupandPlayback&quot;>Setup tools and initiate test execution&lt;/a> &lt;a&#xD;
    href=&quot;#VerifyTestImplementation&quot;>&lt;img height=&quot;20&quot; alt=&quot;To Verify Test Implementation&quot;&#xD;
    src=&quot;./../../core.base_rup/resources/top.gif&quot; width=&quot;26&quot; border=&quot;0&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    Especially in the case of test automation, the settings within the supporting tools should be changed The objective is&#xD;
    to verify the correct workings of the Test Script by executing the Test Script.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    It's a good idea to perform this step using the same Build version of the software used to implement the Test Scripts.&#xD;
    This eliminates the possibility of problems due to introduced errors in subsequent builds.&#xD;
&lt;/p>&#xD;
&lt;h4>&#xD;
    &lt;a id=&quot;ResolveExecutionErrors&quot; name=&quot;ResolveExecutionErrors&quot;>Resolve execution errors&lt;/a> &lt;a&#xD;
    href=&quot;#VerifyTestImplementation&quot;>&lt;img height=&quot;20&quot; alt=&quot;To Verify Test Implementation&quot;&#xD;
    src=&quot;./../../core.base_rup/resources/top.gif&quot; width=&quot;26&quot; border=&quot;0&quot; />&lt;/a>&#xD;
&lt;/h4>&#xD;
&lt;p>&#xD;
    It's pretty common that some of the things done and approaches used during implementation will need a degree of&#xD;
    adjustment to enable the test to run unattended, especially in regard to executing the test under multiple Test&#xD;
    Environment Configurations.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    In the case of test automation, be prepared to spend some time checking and the tests &quot;function within tolerances&quot; and&#xD;
    adjusting them until they work reliably before you declare the test as implemented. While you might delay this step&#xD;
    until later in the lifecycle (e.g. during Test Suite development), we recommend that you don't: otherwise you could end&#xD;
    up with a significant backlog of failures that need to be addressed.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_WRijgNnnEdmO6L4XMImrsA" name=" Restore test environment to known state " guid="_WRijgNnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;Restore&quot; name=&quot;Restore&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To leave the environment either the way you found it, or in the required state to implement the next&#xD;
                test.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    While this step might seem trivial, but it's an important good habit to form to work effectively with the other testers&#xD;
    on the team-especially where the implementation environment is shared. It's also important to establish a routine that&#xD;
    makes thinking of the system state second nature.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    While in a primarily manual testing effort, it's often simple to identify and fix environment restore problems,&#xD;
    remember that test automation has much less ability to tolerate unanticipated problems with environment state.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_WRijgdnnEdmO6L4XMImrsA" name=" Maintain traceability relationships " guid="_WRijgdnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;Traceability&quot; name=&quot;Traceability&quot;>&lt;/a>&#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table border=&quot;1&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;4&quot; style=&quot;border: 1px solid rgb(128,128,128)&quot;&#xD;
    bordercolorlight=&quot;#808080&quot; bordercolordark=&quot;#808080&quot;>&#xD;
        &lt;tr>&#xD;
            &lt;td width=&quot;5%&quot;>&#xD;
                &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
            &lt;/td>&#xD;
            &lt;td width=&quot;95%&quot;>&#xD;
                To enable impact analysis and assessment reporting to be performed on the traced items.&amp;nbsp;&#xD;
            &lt;/td>&#xD;
        &lt;/tr>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Using the Traceability requirements outlined in the Test Plan, update the traceability relationships as required.&#xD;
&lt;/p></sectionDescription>
  </sections>
  <sections xmi:id="_WRijgtnnEdmO6L4XMImrsA" name=" Evaluate and verify your results " guid="_WRijgtnnEdmO6L4XMImrsA">
    <sectionDescription>&lt;a id=&quot;EvaluateResults&quot; name=&quot;EvaluateResults&quot;>&lt;/a> &#xD;
&lt;div align=&quot;left&quot;>&#xD;
    &lt;table&#xD;
    style=&quot;BORDER-RIGHT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-BOTTOM: rgb(128,128,128) 1px solid&quot;&#xD;
     cellspacing=&quot;0&quot; bordercolordark=&quot;#808080&quot; cellpadding=&quot;4&quot; width=&quot;100%&quot; bordercolorlight=&quot;#808080&quot; border=&quot;1&quot;>&#xD;
        &lt;tbody>&#xD;
            &lt;tr>&#xD;
                &lt;td width=&quot;5%&quot;>&#xD;
                    &lt;b>Purpose:&lt;/b>&amp;nbsp;&#xD;
                &lt;/td>&#xD;
                &lt;td width=&quot;95%&quot;>&#xD;
                    To verify that the task has been completed appropriately and that the resulting work products are&#xD;
                    acceptable.&amp;nbsp;&#xD;
                &lt;/td>&#xD;
            &lt;/tr>&#xD;
        &lt;/tbody>&#xD;
    &lt;/table>&lt;br />&#xD;
&lt;/div>&#xD;
&lt;p>&#xD;
    Now that you have completed the work, it is a good practice to verify that the work was of sufficient value. You should&#xD;
    evaluate whether your work is of appropriate quality, and that it is complete enough to be useful to those team members&#xD;
    who will make subsequent use of it as input to their work. Where possible, use the checklists provided in RUP to verify&#xD;
    that quality and completeness are &quot;good enough&quot;.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Have the people who will use your work as input in performing their downstream tasks take part in reviewing your&#xD;
    interim work. Do this while you still have time available to take action to address their concerns. You should also&#xD;
    evaluate your work against the key input work products to make sure you have represented or considered them&#xD;
    sufficiently and accurately. It may be useful to have the author of the input work product review your work on this&#xD;
    basis.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Try to remember that that RUP is an iterative delivery process and that in many cases work products evolve over time.&#xD;
    As such, it is not usually necessary-and is in many cases counterproductive-to fully-form a work product that will only&#xD;
    be partially used or will not be used at all in immediately subsequent downstream work. This is because there is a high&#xD;
    probability that the situation surrounding the work product will change-and the assumptions made when the work product&#xD;
    was created proven incorrect-before the work product is used, resulting in rework and therefore wasted effort.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Also avoid the trap of spending too many cycles on presentation to the detriment of the value of the content itself. In&#xD;
    project environments where presentation has importance and economic value as a project deliverable, you might want to&#xD;
    consider using an administrative or junior resource to perform work on a work product to improve it's presentation.&#xD;
&lt;/p>&lt;br />&#xD;
&lt;br /></sectionDescription>
  </sections>
  <purpose>&lt;a id=&quot;Top&quot; name=&quot;Top&quot;>&lt;/a>&lt;a id=&quot;XE_system_test__implementation_of&quot; name=&quot;XE_system_test__implementation_of&quot;>&lt;/a> &#xD;
&lt;p>&#xD;
    The purpose of this task is to:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        Implement one or more test work products that enable the validation of the software product through physical&#xD;
        execution&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Develop tests that can be executed in conjunction with other tests as part of a larger test infrastructure&#xD;
    &lt;/li>&#xD;
&lt;/ul></purpose>
</org.eclipse.epf.uma:TaskDescription>
