<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmlns:epf="http://www.eclipse.org/epf" epf:version="1.5.1" xmlns:rmc="http://www.ibm.com/rmc" rmc:version="7.5.1" xmi:id="_2zBuNNnmEdmO6L4XMImrsA" name="test-ideas_list,6.149711039531016E-305" guid="_2zBuNNnmEdmO6L4XMImrsA" changeDate="2006-03-25T09:46:52.234-0800" version="7.1.0">
  <mainDescription>&lt;a id=&quot;Top&quot; name=&quot;Top&quot;>&lt;/a>&lt;a id=&quot;XE_test-ideas_list__concept_of&quot; name=&quot;XE_test-ideas_list__concept_of&quot;>&lt;/a> &#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;Introduction&quot; name=&quot;Introduction&quot;>Introduction&lt;/a>&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Information used in designing tests is gathered from many places: design models, classifier interfaces, statecharts,&#xD;
    and code itself. At some point, this source document information must be transformed into executable tests:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        specific inputs given to the software under test&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        a particular hardware and software configuration&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        initialized to a known state&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        specific results expected&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    It's possible to go directly from source document information to executable tests, but it's often useful to add an&#xD;
    intermediate step. In this step, &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../core.base_rup/guidances/termdefinitions/test_idea_6A36A957.html&quot; target=&quot;_blank&quot;&#xD;
    guid=&quot;_yYDXsNnmEdmO6L4XMImrsA&quot;>&lt;i>test ideas&lt;/i>&lt;/a> are written into a &lt;i>Test-Ideas List&lt;/i>, which is used to create&#xD;
    executable tests.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;TestIdeas&quot; name=&quot;TestIdeas&quot;>What are Test Ideas?&lt;/a>&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    A test idea (sometimes referred to as a &lt;a class=&quot;elementLink&quot;&#xD;
    href=&quot;./../../../core.base_rup/guidances/termdefinitions/test_requirement_E14A2712.html&quot; target=&quot;_blank&quot;&#xD;
    guid=&quot;_yYNIudnmEdmO6L4XMImrsA&quot;>test requirement&lt;/a>) is a brief statement about a test that could be performed. As a&#xD;
    simple example, let's consider a function that calculates a square root and come up with some test ideas:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        give a number that's barely less than zero as input&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        give zero as the input&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        test a number that's a perfect square, like 4 or 16 (is the result exactly 2 or 4?)&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    Each of these ideas could readily be converted into an executable test with exact descriptions of inputs and expected&#xD;
    results.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    There are two advantages to this less-specific intermediate form:&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        test ideas are more reviewable and understandable than complete tests-it's easier to understand the reasoning&#xD;
        behind them&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        test ideas support more powerful tests, as described later under the heading &lt;a href=&quot;#TestDesignUsingTheList&quot;>Test&#xD;
        Design Using the List&lt;/a>&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    The square root examples all describe inputs, but test ideas can describe any of the elements of an executable test.&#xD;
    For example, &quot;print to a LaserJet IIIp&quot; describes an aspect of the &lt;a class=&quot;elementLink&quot;&#xD;
    href=&quot;./../../../core.base_rup/guidances/termdefinitions/test_environment_67E4FF5F.html&quot; target=&quot;_blank&quot;&#xD;
    guid=&quot;_yX5mttnmEdmO6L4XMImrsA&quot;>test environment&lt;/a> to be used for a test, as does &quot;test with database full&quot;, however,&#xD;
    these latter test ideas are very incomplete in themselves: Print &lt;b>what&lt;/b> to the printer? Do &lt;b>what&lt;/b> with that&#xD;
    full database? They do, however, ensure that important ideas aren't forgotten; ideas that will be described in more&#xD;
    detail later in test design.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Test ideas are often based on &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../core.base_rup/guidances/termdefinitions/fault_model_C99EBECA.html&quot; target=&quot;_blank&quot;&#xD;
    guid=&quot;_yJJZCdnmEdmO6L4XMImrsA&quot;>&lt;i>fault models&lt;/i>&lt;/a>; notions of which faults are plausible in software and how those&#xD;
    faults can best be uncovered. For example, consider boundaries. It's safe to assume the square root function can be&#xD;
    implemented something like this:&#xD;
&lt;/p>&#xD;
&lt;blockquote>&#xD;
&lt;pre>&#xD;
double sqrt(double x) {&#xD;
    if (x &amp;lt; 0) &#xD;
      // signal error&#xD;
    ...&#xD;
&lt;/pre>&#xD;
&lt;/blockquote>&#xD;
&lt;p>&#xD;
    It's also plausible that the &lt;b>&amp;lt;&lt;/b> will be incorrectly typed as &lt;b>&amp;lt;=&lt;/b>. People often make that kind of&#xD;
    mistake, so it's worth checking. The fault cannot be detected with &lt;b>X&lt;/b> having the value &lt;b>2&lt;/b>, because both the&#xD;
    incorrect expression (&lt;b>x&amp;lt;=0&lt;/b>) and the correct expression (&lt;b>x&amp;lt;0&lt;/b>) will take the same branch of the&#xD;
    &lt;b>if&lt;/b> statement. Similarly, giving &lt;b>X&lt;/b> the value -&lt;b>5&lt;/b> cannot find the fault. The only way to find it is&#xD;
    to give &lt;b>X&lt;/b> the value &lt;b>0&lt;/b>, which justifies the second test idea.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    In this case, the fault model is explicit. In other cases, it's implicit. For example, whenever a program manipulates a&#xD;
    linked structure, it's good to test it against a circular one. It's possible that many faults could lead to a&#xD;
    mishandled circular structure. For the purposes of testing, they needn't be enumerated-it suffices to know that some&#xD;
    fault is likely enough that the test is worth running.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The following links provide information about getting test ideas from different kinds of fault models. The first two&#xD;
    are explicit fault models; the last uses implicit ones.&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        &lt;a class=&quot;elementLinkWithType&quot;&#xD;
        href=&quot;./../../../core.base_rup/guidances/guidelines/test_ideas_for_booleans_and_boundaries_74AE938C.html&quot;&#xD;
        guid=&quot;1.8659406802663404E-305&quot;>Guideline: Test Ideas for Booleans and Boundaries&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a class=&quot;elementLinkWithType&quot; href=&quot;./../../../core.base_rup/guidances/guidelines/test_ideas_for_method_calls_B0A17E5C.html&quot;&#xD;
        guid=&quot;4.418859682485385E-305&quot;>Guideline: Test Ideas for Method Calls&lt;/a>&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        &lt;a class=&quot;elementLinkWithType&quot; href=&quot;./../../../core.base_rup/guidances/concepts/test-ideas_catalog_D99926DE.html&quot;&#xD;
        guid=&quot;6.368392607593696E-305&quot;>Concept: Test-Ideas Catalog&lt;/a>&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    These fault models can be applied to many different work products. For example, the first one describes what to do with&#xD;
    Boolean expressions. Such expressions can be found in code, in guard conditions, in statecharts and sequence diagrams,&#xD;
    and in natural-language descriptions of method behaviors (such as you might find in a published API).&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Occasionally it's also helpful to have guidelines for specific work products. See &lt;a class=&quot;elementLinkWithType&quot;&#xD;
    href=&quot;./../../../core.base_rup/guidances/guidelines/test_ideas_for_statechart_and_flow_diagrams_B881354C.html&quot;&#xD;
    guid=&quot;3.794638918140148E-305&quot;>Guideline: Test Ideas for Statechart and Flow Diagrams&lt;/a>.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    A particular Test-Ideas List might contain test ideas from many fault models, and those fault models could be derived&#xD;
    from more than one work product.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;TestDesignUsingTheList&quot; name=&quot;TestDesignUsingTheList&quot;>Test Design Using the List&lt;/a>&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    Let's suppose you're designing tests for a method that searches for a string in a sequential collection. It can either&#xD;
    obey case or ignore case in its search, and it returns the index of the first match found or -1 if no match is found.&#xD;
&lt;/p>&#xD;
&lt;blockquote>&#xD;
&lt;pre>&#xD;
int Collection.find(String string,&#xD;
                    Boolean ignoreCase);&#xD;
&lt;/pre>&#xD;
&lt;/blockquote>&#xD;
&lt;p>&#xD;
    Here are some test ideas for this method:&#xD;
&lt;/p>&#xD;
&lt;ol>&#xD;
    &lt;li>&#xD;
        match found in the first position&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        match found in the last position&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        no match found&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        two or more matches found in the collection&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        case is ignored; match found, but it wouldn't match if case was obeyed&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        case is obeyed; an exact match is found&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        case is obeyed; a string that would have matched if case were ignored is skipped&#xD;
    &lt;/li>&#xD;
&lt;/ol>&#xD;
&lt;p>&#xD;
    It would be simple to implement these seven tests, one for each test idea. However, different test ideas can be&#xD;
    combined into a single test. For example, the following test &lt;i>satisfies&lt;/i> test ideas 2, 6, and 7:&#xD;
&lt;/p>&#xD;
&lt;blockquote>&#xD;
    &lt;p>&#xD;
        Setup: collection initialized to [&quot;dawn&quot;, &quot;Dawn&quot;]&lt;br />&#xD;
         Invocation: collection.find(&quot;Dawn&quot;, false)&lt;br />&#xD;
         Expected result: return value is 1 (it would be 0 if &quot;dawn&quot; were not skipped)&#xD;
    &lt;/p>&#xD;
&lt;/blockquote>&#xD;
&lt;p>&#xD;
    Making test ideas nonspecific makes them easier to combine.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    It's possible to satisfy all of the test ideas in three tests. Why would three tests that satisfy seven test ideas be&#xD;
    better than seven separate tests?&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        When you're creating a large number of simple tests, it's common to create test N+1 by copying test N and tweaking&#xD;
        it just enough to satisfy the new test idea. The result, especially in more complex software, is that test N+1&#xD;
        probably exercises the program in almost the same way as test N. It takes almost exactly the same path through the&#xD;
        code.&lt;br />&#xD;
        &lt;br />&#xD;
         A smaller number of tests, each satisfying several test ideas, doesn't allow a &quot;copy and tweak&quot; approach. Each&#xD;
        test will be somewhat different from the last, exercising the code in different ways and taking different&#xD;
        paths.&lt;br />&#xD;
        &lt;br />&#xD;
         Why would that be better? If the Test-Ideas List were complete, with a test idea for every fault in the program,&#xD;
        it wouldn't matter how you wrote the tests. But the list is always missing some test ideas that could find bugs. By&#xD;
        having each test do very different things from the last one-by adding seemingly unneeded variety-you increase the&#xD;
        chance that one of the tests will stumble over a bug by sheer dumb luck. In effect, smaller, more complex tests&#xD;
        increase the chance the test will satisfy a test idea that you didn't know you needed.&lt;br />&#xD;
        &lt;br />&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Sometimes when you're creating more complex tests, new test ideas come to mind. That happens less often with simple&#xD;
        tests, because so much of what you're doing is exactly like the last test, which dulls your mind.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    However, there are reasons for not creating complex tests.&#xD;
&lt;/p>&#xD;
&lt;ul>&#xD;
    &lt;li>&#xD;
        If each test satisfies a single test idea and the test for idea 2 fails, you immediately know the most likely&#xD;
        cause: the program doesn't handle a match in the last position. If a test satisfies ideas 2, 6, and 7, then&#xD;
        isolating the failure is harder.&lt;br />&#xD;
        &lt;br />&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Complex tests are more difficult to understand and maintain. The intent of the test is less obvious.&lt;br />&#xD;
        &lt;br />&#xD;
    &lt;/li>&#xD;
    &lt;li>&#xD;
        Complex tests are more difficult to create. Constructing a test that satisfies five test ideas often takes more&#xD;
        time than constructing five tests that each satisfy one. Moreover, it's easier to make mistakes-to think you're&#xD;
        satisfying all five when you're only satisfying four.&#xD;
    &lt;/li>&#xD;
&lt;/ul>&#xD;
&lt;p>&#xD;
    In practice, you must find a reasonable balance between complexity and simplicity. For example, the first tests you&#xD;
    subject the software to (typically the &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../core.base_rup/guidances/termdefinitions/smoke_test_961BBC4D.html&quot; target=&quot;_blank&quot;&#xD;
    guid=&quot;_yVhBFtnmEdmO6L4XMImrsA&quot;>&lt;i>smoke tests&lt;/i>&lt;/a>) should be simple, easy to understand and maintain, and intended&#xD;
    to catch the most obvious problems. Later tests should be more complex, but not so complex they are not maintainable.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    After you've finished a set of tests, it's good to check them against the characteristic test design mistakes discussed&#xD;
    in &lt;a class=&quot;elementLinkWithType&quot;&#xD;
    href=&quot;./../../../core.base_rup/guidances/concepts/developer_testing_D800236F.html#TestDesignMistakes&quot;&#xD;
    guid=&quot;7.256588791264849E-307&quot;>Concept: Developer Testing&lt;/a>.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;UsingTestIdeasBeforeTest&quot; name=&quot;UsingTestIdeasBeforeTest&quot;>Using Test Ideas Before Testing&lt;/a>&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    A Test-Ideas List is useful for reviews and inspections of design work products. For example, consider this part of a&#xD;
    &lt;a class=&quot;elementLink&quot; href=&quot;./../../../core.base_rup/guidances/termdefinitions/design_model_BAFECB4C.html&quot; target=&quot;_blank&quot;&#xD;
    guid=&quot;_yF4CltnmEdmO6L4XMImrsA&quot;>design model&lt;/a> showing the association between Department and Employee classes.&#xD;
&lt;/p>&#xD;
&lt;p align=&quot;center&quot;>&#xD;
    &lt;img height=&quot;45&quot; alt=&quot;Design Model Example Image&quot; src=&quot;resources/tstidslst-img1.gif&quot; width=&quot;223&quot; />&#xD;
&lt;/p>&#xD;
&lt;p class=&quot;picturetext&quot;>&#xD;
    Figure 1: Association between Department and Employee Classes&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The rules for creating test ideas from such a model would ask you to consider the case where a department has many&#xD;
    employees. By walking through a design and asking &quot;what if, at this point, the department has many employees?&quot;, you&#xD;
    might discover design or analysis errors. For example, you might realize that only one employee at a time can be&#xD;
    transferred between departments. That might be a problem if the corporation is prone to sweeping reorganizations where&#xD;
    many employees need to be transferred.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    Such faults, cases where a possibility was overlooked, are called &lt;i>faults of omission&lt;/i>. Just like the faults&#xD;
    themselves, you have probably omitted tests that detect these faults from your testing effort. For example, see &lt;a&#xD;
    class=&quot;elementLinkWithUserText&quot; href=&quot;./../../../core.base_rup/customcategories/references_56F06DFD.html#GLA81&quot;&#xD;
    guid=&quot;7.755968586980351E-308&quot;>[GLA81]&lt;/a>, &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../core.base_rup/customcategories/references_56F06DFD.html#OST84&quot; guid=&quot;7.755968586980351E-308&quot;>[OST84]&lt;/a>, &lt;a&#xD;
    class=&quot;elementLinkWithUserText&quot; href=&quot;./../../../core.base_rup/customcategories/references_56F06DFD.html#BAS87&quot;&#xD;
    guid=&quot;7.755968586980351E-308&quot;>[BAS87]&lt;/a>, &lt;a class=&quot;elementLinkWithUserText&quot;&#xD;
    href=&quot;./../../../core.base_rup/customcategories/references_56F06DFD.html#MAR00&quot; guid=&quot;7.755968586980351E-308&quot;>[MAR00]&lt;/a>, and&#xD;
    other studies that show how often faults of omission escape into deployment.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The role of testing in design activities is discussed further in &lt;a class=&quot;elementLinkWithType&quot;&#xD;
    href=&quot;./../../../core.base_rup/guidances/concepts/test-first_design_6124EA6D.html&quot; guid=&quot;2.5962561793181055E-305&quot;>Concept:&#xD;
    Test-first Design&lt;/a>.&#xD;
&lt;/p>&#xD;
&lt;h3>&#xD;
    &lt;a id=&quot;TestIdeasTraceability&quot; name=&quot;TestIdeasTraceability&quot;>Test Ideas and Traceability&lt;/a>&#xD;
&lt;/h3>&#xD;
&lt;p>&#xD;
    &lt;a class=&quot;elementLink&quot; href=&quot;./../../../core.base_rup/guidances/termdefinitions/traceability_84090089.html&quot; target=&quot;_blank&quot;&#xD;
    guid=&quot;_yY8vkNnmEdmO6L4XMImrsA&quot;>traceability&lt;/a> is a matter of tradeoffs. Is its value worth the cost of maintaining&#xD;
    it? This question needs to be considered during &lt;a class=&quot;elementLinkWithType&quot;&#xD;
    href=&quot;./../../../core.base_rup/tasks/define_assessment_and_traceability_needs_19C5C9FE.html&quot;&#xD;
    guid=&quot;{F6F9BB36-5A72-421E-B195-8937E0C46AF8}&quot;>Task: Define Assessment and Traceability Needs&lt;/a>.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    When traceability is worthwhile, it's conventional to trace tests back to the work products that inspired them. For&#xD;
    example, you might have traceability between an API and its tests. If the API changes, you know which tests to change.&#xD;
    If the code (that implements the API) changes, you know which tests to run. If a test puzzles you, you can find the API&#xD;
    it's intended to test.&#xD;
&lt;/p>&#xD;
&lt;p>&#xD;
    The Test-Ideas List adds another level of traceability. You can trace from a test to the test ideas it satisfies, and&#xD;
    then from the test ideas to the original work product.&#xD;
&lt;/p>&lt;br />&#xD;
&lt;br /></mainDescription>
</org.eclipse.epf.uma:ContentDescription>
